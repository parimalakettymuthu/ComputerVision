{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu118\n",
      "0.16.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Getting a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True, \n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: : torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '9')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAkhklEQVR4nO3de3SU9b3v8c/kNgSYTAghNwkYUEAFYkshplhESYG0xwPK7tHWswo9Li0YXEXarQu3ilq70+La1lOLes7aLdS1xNuqyJZtOVVogrQJyu1QaptCGgUlCRfNTMh1kvmdPzhGI9ffwyS/JLxfa81aZOb58Px4eJJPnszMNz5jjBEAAL0szvUCAAAXJwoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQT0kp07d2ru3LlKSUlRIBDQ7NmztWfPHtfLApzxMQsO6Hm7du3S9OnTlZubq+9///uKRqN6+umn9fHHH+udd97R+PHjXS8R6HUUENALvvnNb6qiokL79+/X8OHDJUm1tbUaN26cZs+erd/+9reOVwj0Pn4EB/SCt99+W0VFRV3lI0nZ2dm67rrrtHHjRp04ccLh6gA3KCCgF7S1tSk5OfmU+wcPHqz29nbt27fPwaoAtyggoBeMHz9elZWV6uzs7Lqvvb1d27dvlyR99NFHrpYGOEMBAb3grrvu0t///nfdfvvteu+997Rv3z5997vfVW1trSSppaXF8QqB3kcBAb1g8eLFuv/++7Vu3TpdddVVmjRpkqqrq3XvvfdKkoYOHep4hUDvo4CAXvKTn/xE9fX1evvtt7V37169++67ikajkqRx48Y5Xh3Q+3gZNuDQtGnTVFtbqw8++EBxcXw/iIsLZzzgyEsvvaR3331Xy5Yto3xwUeIKCOgFW7du1aOPPqrZs2dr+PDhqqys1Jo1a/T1r39dr7/+uhISElwvEeh1nPVAL7jkkksUHx+vxx9/XI2NjcrLy9Njjz2m5cuXUz64aHEFBABwgh88AwCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgRJ97A0I0GtXhw4cVCATk8/lcLwcAYMkYo8bGRuXk5Jx1ykefK6DDhw8rNzfX9TIAABfo0KFDGjly5Bkf73MFFAgEJEnX6htKUKLj1QAAbHUoom16o+vr+Zn0WAGtXr1ajz/+uOrq6pSfn6+nnnpK06ZNO2fu0x+7JShRCT4KCAD6nf8/X+dcT6P0yIsQXnrpJS1fvlwrV67Url27lJ+frzlz5ujIkSM9sTsAQD/UIwX0xBNP6I477tD3vvc9XXnllXr22Wc1ePBg/frXv+6J3QEA+qGYF1B7e7t27typoqKiz3YSF6eioiJVVFScsn1bW5vC4XC3GwBg4It5AR07dkydnZ3KzMzsdn9mZqbq6upO2b60tFTBYLDrxivgAODi4PyNqCtWrFAoFOq6HTp0yPWSAAC9IOavgktPT1d8fLzq6+u73V9fX6+srKxTtvf7/fL7/bFeBgCgj4v5FVBSUpKmTJmizZs3d90XjUa1efNmFRYWxnp3AIB+qkfeB7R8+XItXLhQX/nKVzRt2jQ9+eSTampq0ve+972e2B0AoB/qkQK65ZZbdPToUT300EOqq6vT1VdfrU2bNp3ywgQAwMXLZ4wxrhfxeeFwWMFgUDM1j0kIANAPdZiIyrRBoVBIKSkpZ9zO+avgAAAXJwoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOBEgusFAH2Kz2efMSb26ziN+OFp1plP5ozztK+UdZWectY8HG9fQqJ1xkTarTN9npdz1aseOse5AgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJxhGCnyOLz7eOmM6OqwzcVdfaZ356/eH2u+nxToiSUpsmmadSWiJ2u/n9zusM706WNTLsFQP55B89tcCvXkcfAl2VeEzRjqPTwuugAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACYaRAp9jO3RR8jaM9NCcVOvMbYVvW2f+eHSMdUaSPvBnWWdMsv1+EooKrTPjnv7IOtPx/kHrjCTJGPuIh/PBi/hhw7wFOzvtI+Gw1fbGnN8x4AoIAOAEBQQAcCLmBfTwww/L5/N1u02YMCHWuwEA9HM98hzQVVddpbfeeuuznXj4uToAYGDrkWZISEhQVpb9k5gAgItHjzwHtH//fuXk5GjMmDG67bbbdPDgmV+B0tbWpnA43O0GABj4Yl5ABQUFWrt2rTZt2qRnnnlGNTU1+trXvqbGxsbTbl9aWqpgMNh1y83NjfWSAAB9UMwLqLi4WN/61rc0efJkzZkzR2+88YYaGhr08ssvn3b7FStWKBQKdd0OHToU6yUBAPqgHn91QGpqqsaNG6cDBw6c9nG/3y+/39/TywAA9DE9/j6gEydOqLq6WtnZ2T29KwBAPxLzAvrRj36k8vJyvf/++/rTn/6km266SfHx8fr2t78d610BAPqxmP8I7sMPP9S3v/1tHT9+XCNGjNC1116ryspKjRgxIta7AgD0YzEvoBdffDHWfyXQa6Ktrb2yn/YvnbDO/FNwh3VmUFzEOiNJ5XFR68xHW+xfwdo52f44fPBEwDoT3f1V64wkDd9nP7gzZXetdebYjEusM0en2A9KlaTMSvvMsLeqrbY30Xbp2Lm3YxYcAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADjR47+QDnDC5/OWM/YDHk/8t2usM9+9ssw6Ux2xnyg/Mulj64wkfStnp33ov9tnfll1nXWm6R9B60zcEG+DO+uusf8e/aN59v9PJtJhnRm2y9uX77iF9daZcPsYq+07Iq3ShvNYi/VKAACIAQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJxgGjZ6l9cp1X3YNfe9Y525fuh7PbCSU10ib1Ogm0ySdaahc4h1ZuWV/2mdOTouYJ2JGG9f6v59/1etMyc8TOuO77D/vLjmf+y2zkjSgrR3rTOrfjvJavsOEzmv7bgCAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnGEaK3mW8Dcfsy/afyLDOHE8Zap2p60i1zgyPP2GdkaRAXIt15tLEY9aZo532g0XjE6PWmXYTb52RpEeuet0603pFonUm0ddpnfnqoMPWGUn61nvftc4M0T887etcuAICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcYRgpcoBF++4Gfg3wR60ySr8M6czgyzDojSftbxltn/h62H8o6N/Mv1pmIh8Gi8fI2BNfLkNCcxE+sM63GfoCp/Rl00vRM+8Giezzu61y4AgIAOEEBAQCcsC6grVu36sYbb1ROTo58Pp9ee+21bo8bY/TQQw8pOztbycnJKioq0v79+2O1XgDAAGFdQE1NTcrPz9fq1atP+/iqVav0i1/8Qs8++6y2b9+uIUOGaM6cOWptbb3gxQIABg7rFyEUFxeruLj4tI8ZY/Tkk0/qgQce0Lx58yRJzz33nDIzM/Xaa6/p1ltvvbDVAgAGjJg+B1RTU6O6ujoVFRV13RcMBlVQUKCKiorTZtra2hQOh7vdAAADX0wLqK6uTpKUmZnZ7f7MzMyux76otLRUwWCw65abmxvLJQEA+ijnr4JbsWKFQqFQ1+3QoUOulwQA6AUxLaCsrCxJUn19fbf76+vrux77Ir/fr5SUlG43AMDAF9MCysvLU1ZWljZv3tx1Xzgc1vbt21VYWBjLXQEA+jnrV8GdOHFCBw4c6Pq4pqZGe/bsUVpamkaNGqVly5bpscce0+WXX668vDw9+OCDysnJ0fz582O5bgBAP2ddQDt27ND111/f9fHy5cslSQsXLtTatWt17733qqmpSXfeeacaGhp07bXXatOmTRo0aFDsVg0A6Pd8xhhvU/p6SDgcVjAY1EzNU4LPfkAf+jifzz4Sbz980nTYD+6UpPhh9sM7b634s/1+fPafdkc7AtaZ1Phm64wklTfYDyP9y/HTP897No+O/w/rzK7mS60zOUn2A0Ilb8fv/fZ068zl/tO/SvhsfvdJvnVGknIHfWyd+f2yGVbbd3S0alvZIwqFQmd9Xt/5q+AAABcnCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnLD+dQzABfEwfN2XYH+aep2Gfej2K6wzNwx+3Trzp9ZLrDMjEhqtMxFjP0lckrL9IetMILPVOtPQOdg6k5ZwwjrT2JlsnZGkwXFt1hkv/09fTjpmnbnnrS9bZyQpMPG4dSYl0e5aJXqe1zZcAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAEwwjRa/yJSZZZ6Kt9kMuvUr/c7t15lhnonUmNa7ZOpPk67TOtHscRvrVtBrrzFEPAz93teRZZwLxLdaZEXH2A0IlKTfRfnDnn1tzrTNvNF1mnbn9v7xlnZGkF/73160zSZv+ZLV9nImc33bWKwEAIAYoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4MTFPYzU5/MWS7AfPumL99D1cfaZaGub/X6i9kMuvTIR+2Gfvel//q9fWmcOdaRaZ+oi9pnUePsBpp3ydo5XtgStM4Pizm8A5eeNSAhbZ8JR+6GnXjVGB1lnIh4GwHo5dvcN32+dkaRXQ0Wecj2BKyAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcGLADCP1Jdj/U0xHh6d9eRmoaexnDQ5ILfOmWWcOzbcflnrbl96xzkhSXUfAOrO7+VLrTDC+xTozJM5+0GyrsR+cK0mH24dZZ7wM1ExLOGGdyfAwwLTTePte+6OI/XHwwsug2Q877I+dJDX+10brTOpznnZ1TlwBAQCcoIAAAE5YF9DWrVt14403KicnRz6fT6+99lq3xxctWiSfz9ftNnfu3FitFwAwQFgXUFNTk/Lz87V69eozbjN37lzV1tZ23V544YULWiQAYOCxfua+uLhYxcXFZ93G7/crKyvL86IAAANfjzwHVFZWpoyMDI0fP15LlizR8ePHz7htW1ubwuFwtxsAYOCLeQHNnTtXzz33nDZv3qyf/exnKi8vV3FxsTo7T/9S2tLSUgWDwa5bbm5urJcEAOiDYv4+oFtvvbXrz5MmTdLkyZM1duxYlZWVadasWadsv2LFCi1fvrzr43A4TAkBwEWgx1+GPWbMGKWnp+vAgQOnfdzv9yslJaXbDQAw8PV4AX344Yc6fvy4srOze3pXAIB+xPpHcCdOnOh2NVNTU6M9e/YoLS1NaWlpeuSRR7RgwQJlZWWpurpa9957ry677DLNmTMnpgsHAPRv1gW0Y8cOXX/99V0ff/r8zcKFC/XMM89o7969+s1vfqOGhgbl5ORo9uzZ+vGPfyy/3x+7VQMA+j2fMca4XsTnhcNhBYNBzdQ8Jfi8DVLsixKy7d8XFcnLtM58fMVg60xzls86I0lXf+Ov1plFmdusM0c77Z8XTPR5GzTb2JlsnclKbLDObAldaZ0ZmmA/jNTL0FNJ+nLy+9aZhqj9uZeT8Il15r4D/2SdyRxsP4BTkv599BvWmYiJWmeqIvbfoAfi7IciS9LbzZdZZ9ZfOcJq+w4TUZk2KBQKnfV5fWbBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwImY/0puV9qKp1pnMv7lH572dXXKh9aZK5Ptp0C3Ru2ngQ+Ki1hn3mu5xDojSc3RJOvM/nb7qeChDvspy/E++4nEknSkPWCd+beaIuvM5mnPWmceODzXOhOX7G3Y/fHOodaZBUPDHvZkf45/f9RW68yYpCPWGUna2GT/izQPR4ZZZzITQ9aZSxOPWmck6ebA360z62U3Dft8cQUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE702WGkvoQE+Xznv7yCf33Xeh+zAn+xzkhSs/FbZ7wMFvUy1NCLYEKzp1xbxP70ORJJ8bQvW+P8dZ5yN6Xssc5s/WWBdeba1rutM9U3rLHObG6Jt85I0tEO+/+nW2tusM7sOphrnbnm0hrrzKTAR9YZydsg3EB8q3Um0ddhnWmK2n8dkqTKVvtBsz2FKyAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcKLPDiOtXTJF8f5B5739w8GnrPex7uNrrDOSlDvoY+vM6KRj1pn85A+sM14E4uyHJ0rS+BT7AYobm0ZaZ8oaJlhnshMbrDOS9HbzWOvMiw8/bp1ZdM8PrTOFbyy2zoQv9fY9ZscQY51JyT9unXngS/9pnUnydVpnGjrth4pKUpq/yTqTGu9tuK8tL0ORJSkQ12KdiR9/mdX2prNN2n/u7bgCAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAn+uww0sFHoopPip739hvDV1vvY0zyUeuMJB2LBKwz/+fEJOvMyORPrDPBePtBg5f566wzkrSnNdU6s+noVdaZnOSwdaY+ErTOSNLxyBDrTHPUfijkr37+hHXm3+qLrDM3pe2yzkhSfpL9YNGGqP33s++1Z1lnGqPnP6T4U60m0TojSSEPQ0wDHj4HI8b+S3G8Of+vj5+XGmc/LDU8abjV9h2RVoaRAgD6LgoIAOCEVQGVlpZq6tSpCgQCysjI0Pz581VVVdVtm9bWVpWUlGj48OEaOnSoFixYoPr6+pguGgDQ/1kVUHl5uUpKSlRZWak333xTkUhEs2fPVlPTZ7+06Z577tHrr7+uV155ReXl5Tp8+LBuvvnmmC8cANC/WT3ztWnTpm4fr127VhkZGdq5c6dmzJihUCikX/3qV1q3bp1uuOEGSdKaNWt0xRVXqLKyUtdc4+03kAIABp4Leg4oFApJktLS0iRJO3fuVCQSUVHRZ6/WmTBhgkaNGqWKiorT/h1tbW0Kh8PdbgCAgc9zAUWjUS1btkzTp0/XxIkTJUl1dXVKSkpSampqt20zMzNVV3f6l/qWlpYqGAx23XJzc70uCQDQj3guoJKSEu3bt08vvvjiBS1gxYoVCoVCXbdDhw5d0N8HAOgfPL0RdenSpdq4caO2bt2qkSNHdt2flZWl9vZ2NTQ0dLsKqq+vV1bW6d9w5vf75ffbv5EPANC/WV0BGWO0dOlSrV+/Xlu2bFFeXl63x6dMmaLExERt3ry5676qqiodPHhQhYWFsVkxAGBAsLoCKikp0bp167RhwwYFAoGu53WCwaCSk5MVDAZ1++23a/ny5UpLS1NKSoruvvtuFRYW8go4AEA3VgX0zDPPSJJmzpzZ7f41a9Zo0aJFkqSf//zniouL04IFC9TW1qY5c+bo6aefjsliAQADh88YY1wv4vPC4bCCwaBmXPugEhLOf+jg1Cd3Wu9rXzjHOiNJmYMarTOTh35onalqth/UeLglxTozOCFinZGk5Hj7XIexf91Lht/+eI/y2w/TlKRAnP0gySRfp3Wm08Prf65KOmydOdgxzDojSXUdqdaZ95rtP5+GJdgPxvyzh8/b5o4k64wktXXaP03e2mGfCfpbrTNT0z6wzkhSnOy/5K/7j+usto+2tuofj/2LQqGQUlLO/DWJWXAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwwtNvRO0Ncdv2Ks6XeN7bv/L76db7eHDeK9YZSSpvmGCd2Vg3yToTbrf/TbEjBjdZZ1IS7adNS1Jaov2+gh6mHw/ydVhnPukYYp2RpLa48z/nPtUpn3Wmri1onflj9HLrTCQab52RpDYPOS/T0T9uT7fO5CSHrDONHec/Wf/z3m9Ms84cCw21zrQOtv9SvK1zrHVGkuZm/cU6k3zE7hzvbDu/7bkCAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnfMYY43oRnxcOhxUMBjVT85RgMYzUi9Bt13jKjbmryjozLbXGOrMrPMo6c9DD8MRI1Nv3IYlxUevM4MR268wgD0Muk+I7rTOSFCf7T4eoh2GkQ+Ltj8OQhDbrTEpCq3VGkgLx9rk4n/354EW8h/+jd0KXxn4hZxDw8P/UYew/BwuD1dYZSfp1zVetM8FvHLDavsNEVKYNCoVCSklJOeN2XAEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBN9dxhp3M12w0ij3oZP9pamBQXWmYL737XPBOwHFE5IqrfOSFKi7IdPDvIwsHJInP2wz1aPp7WX78i2teRaZzo97GnLJ1dYZyIehlxKUn3zmQdInkmixwGwtqLG/nxo6fA22DjUMsg6Ex9nf+61lqVbZ4a/Zz+kV5L8b9h/XbHFMFIAQJ9GAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACf67jBSzbMbRgrPfFMnecq1ZCVbZ/zH26wzjaPt95NS3WSdkaS4tg7rTPT//tXTvoCBimGkAIA+jQICADhhVUClpaWaOnWqAoGAMjIyNH/+fFVVVXXbZubMmfL5fN1uixcvjumiAQD9n1UBlZeXq6SkRJWVlXrzzTcViUQ0e/ZsNTV1/3n7HXfcodra2q7bqlWrYrpoAED/l2Cz8aZNm7p9vHbtWmVkZGjnzp2aMWNG1/2DBw9WVlZWbFYIABiQLug5oFAoJElKS0vrdv/zzz+v9PR0TZw4UStWrFBzc/MZ/462tjaFw+FuNwDAwGd1BfR50WhUy5Yt0/Tp0zVx4sSu+7/zne9o9OjRysnJ0d69e3XfffepqqpKr7766mn/ntLSUj3yyCNelwEA6Kc8vw9oyZIl+t3vfqdt27Zp5MiRZ9xuy5YtmjVrlg4cOKCxY8ee8nhbW5va2j57b0g4HFZubi7vA+pFvA/oM7wPCLhw5/s+IE9XQEuXLtXGjRu1devWs5aPJBUUFEjSGQvI7/fL7/d7WQYAoB+zKiBjjO6++26tX79eZWVlysvLO2dmz549kqTs7GxPCwQADExWBVRSUqJ169Zpw4YNCgQCqqurkyQFg0ElJyerurpa69at0ze+8Q0NHz5ce/fu1T333KMZM2Zo8uTJPfIPAAD0T1YF9Mwzz0g6+WbTz1uzZo0WLVqkpKQkvfXWW3ryySfV1NSk3NxcLViwQA888EDMFgwAGBisfwR3Nrm5uSovL7+gBQEALg6eX4aNgcO8+2dPuUExXseZpPypl3YkKdp7uwIuegwjBQA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcCLB9QK+yBgjSepQRDKOFwMAsNahiKTPvp6fSZ8roMbGRknSNr3heCUAgAvR2NioYDB4xsd95lwV1cui0agOHz6sQCAgn8/X7bFwOKzc3FwdOnRIKSkpjlboHsfhJI7DSRyHkzgOJ/WF42CMUWNjo3JychQXd+ZnevrcFVBcXJxGjhx51m1SUlIu6hPsUxyHkzgOJ3EcTuI4nOT6OJztyudTvAgBAOAEBQQAcKJfFZDf79fKlSvl9/tdL8UpjsNJHIeTOA4ncRxO6k/Hoc+9CAEAcHHoV1dAAICBgwICADhBAQEAnKCAAABOUEAAACf6TQGtXr1al156qQYNGqSCggK98847rpfU6x5++GH5fL5utwkTJrheVo/bunWrbrzxRuXk5Mjn8+m1117r9rgxRg899JCys7OVnJysoqIi7d+/381ie9C5jsOiRYtOOT/mzp3rZrE9pLS0VFOnTlUgEFBGRobmz5+vqqqqbtu0traqpKREw4cP19ChQ7VgwQLV19c7WnHPOJ/jMHPmzFPOh8WLFzta8en1iwJ66aWXtHz5cq1cuVK7du1Sfn6+5syZoyNHjrheWq+76qqrVFtb23Xbtm2b6yX1uKamJuXn52v16tWnfXzVqlX6xS9+oWeffVbbt2/XkCFDNGfOHLW2tvbySnvWuY6DJM2dO7fb+fHCCy/04gp7Xnl5uUpKSlRZWak333xTkUhEs2fPVlNTU9c299xzj15//XW98sorKi8v1+HDh3XzzTc7XHXsnc9xkKQ77rij2/mwatUqRys+A9MPTJs2zZSUlHR93NnZaXJyckxpaanDVfW+lStXmvz8fNfLcEqSWb9+fdfH0WjUZGVlmccff7zrvoaGBuP3+80LL7zgYIW944vHwRhjFi5caObNm+dkPa4cOXLESDLl5eXGmJP/94mJieaVV17p2uavf/2rkWQqKipcLbPHffE4GGPMddddZ37wgx+4W9R56PNXQO3t7dq5c6eKioq67ouLi1NRUZEqKiocrsyN/fv3KycnR2PGjNFtt92mgwcPul6SUzU1Naqrq+t2fgSDQRUUFFyU50dZWZkyMjI0fvx4LVmyRMePH3e9pB4VCoUkSWlpaZKknTt3KhKJdDsfJkyYoFGjRg3o8+GLx+FTzz//vNLT0zVx4kStWLFCzc3NLpZ3Rn1uGvYXHTt2TJ2dncrMzOx2f2Zmpv72t785WpUbBQUFWrt2rcaPH6/a2lo98sgj+trXvqZ9+/YpEAi4Xp4TdXV1knTa8+PTxy4Wc+fO1c0336y8vDxVV1fr/vvvV3FxsSoqKhQfH+96eTEXjUa1bNkyTZ8+XRMnTpR08nxISkpSampqt20H8vlwuuMgSd/5znc0evRo5eTkaO/evbrvvvtUVVWlV1991eFqu+vzBYTPFBcXd/158uTJKigo0OjRo/Xyyy/r9ttvd7gy9AW33npr158nTZqkyZMna+zYsSorK9OsWbMcrqxnlJSUaN++fRfF86Bnc6bjcOedd3b9edKkScrOztasWbNUXV2tsWPH9vYyT6vP/wguPT1d8fHxp7yKpb6+XllZWY5W1TekpqZq3LhxOnDggOulOPPpOcD5caoxY8YoPT19QJ4fS5cu1caNG/WHP/yh2+8Py8rKUnt7uxoaGrptP1DPhzMdh9MpKCiQpD51PvT5AkpKStKUKVO0efPmrvui0ag2b96swsJChytz78SJE6qurlZ2drbrpTiTl5enrKysbudHOBzW9u3bL/rz48MPP9Tx48cH1PlhjNHSpUu1fv16bdmyRXl5ed0enzJlihITE7udD1VVVTp48OCAOh/OdRxOZ8+ePZLUt84H16+COB8vvvii8fv9Zu3atea9994zd955p0lNTTV1dXWul9arfvjDH5qysjJTU1Nj/vjHP5qioiKTnp5ujhw54nppPaqxsdHs3r3b7N6920gyTzzxhNm9e7f54IMPjDHG/PSnPzWpqalmw4YNZu/evWbevHkmLy/PtLS0OF55bJ3tODQ2Npof/ehHpqKiwtTU1Ji33nrLfPnLXzaXX365aW1tdb30mFmyZIkJBoOmrKzM1NbWdt2am5u7tlm8eLEZNWqU2bJli9mxY4cpLCw0hYWFDlcde+c6DgcOHDCPPvqo2bFjh6mpqTEbNmwwY8aMMTNmzHC88u76RQEZY8xTTz1lRo0aZZKSksy0adNMZWWl6yX1ultuucVkZ2ebpKQkc8kll5hbbrnFHDhwwPWyetwf/vAHI+mU28KFC40xJ1+K/eCDD5rMzEzj9/vNrFmzTFVVldtF94CzHYfm5mYze/ZsM2LECJOYmGhGjx5t7rjjjgH3Tdrp/v2SzJo1a7q2aWlpMXfddZcZNmyYGTx4sLnppptMbW2tu0X3gHMdh4MHD5oZM2aYtLQ04/f7zWWXXWb++Z//2YRCIbcL/wJ+HxAAwIk+/xwQAGBgooAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJ/4fSFZm765APLcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image, label = train_data[0]\n",
    "print(f\"Image shape: : {image.shape}\")\n",
    "plt.imshow(image.squeeze())\n",
    "plt.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.squeeze(), cmap='grey')\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows*cols+1):\n",
    "    #print(i)\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap=\"grey\")\n",
    "    plt.title(label)\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: ToTensor())"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x224ee2ed150>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x224ee69bc50>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2. prepare data loader - makes dataset iterable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#Batchsize hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "#Datasets to iterable\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False)\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders: (<torch.utils.data.dataloader.DataLoader object at 0x00000224EE2ED150>, <torch.utils.data.dataloader.DataLoader object at 0x00000224EE69BC50>)\n",
      "Length of Train DataLoaders: 1875 batched of 32\n",
      "Length of Test DataLoaders: 313 batched of 32\n"
     ]
    }
   ],
   "source": [
    "print(f\"DataLoaders: {train_dataloader, test_dataloader}\")\n",
    "print(f\"Length of Train DataLoaders: {len(train_dataloader)} batched of {BATCH_SIZE}\")\n",
    "print(f\"Length of Test DataLoaders: {len(test_dataloader)} batched of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([1, 28, 28])\n",
      "label: 8, label size: torch.Size([])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#torch.manual_seed(42)\n",
    "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(label)\n",
    "plt.axis(False)\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"label: {label}, label size: {label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Model_0: Build a baseline model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before flattening: torch.Size([1, 28, 28]) --> [color_channels, height, width]\n",
      "shape before flattening: torch.Size([1, 784]) --> [color_channels, height*width]\n"
     ]
    }
   ],
   "source": [
    "#flatten layer\n",
    "flatten_model = nn.Flatten()\n",
    "\n",
    "x = train_features_batch[0]\n",
    "x.shape\n",
    "\n",
    "#Flatten the sample\n",
    "output = flatten_model(x)\n",
    "\n",
    "#print\n",
    "print(f\"shape before flattening: {x.shape} --> [color_channels, height, width]\")\n",
    "print(f\"shape before flattening: {output.shape} --> [color_channels, height*width]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0039, 0.0039, 0.0000, 0.0000, 0.0078, 0.0078,\n",
       "         0.0000, 0.0000, 0.0039, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.2863, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.3725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.3373, 0.3569, 0.2039, 0.4980, 0.4196, 0.4706, 0.3608, 0.3961, 0.4706,\n",
       "         0.4471, 1.0000, 0.4314, 0.3451, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0706, 0.0824, 0.0706, 0.4588, 0.4118, 0.4980, 0.2588, 0.2235,\n",
       "         0.2588, 0.0824, 0.0510, 0.1922, 0.5137, 0.5765, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.1333, 0.8000, 0.5608, 0.5255, 0.2431, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0039, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0078, 0.0000, 0.0000, 0.0000, 0.9137, 0.9686, 0.5137, 0.4353, 0.6471,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0588, 0.3843, 0.6980, 0.0588, 0.2824,\n",
       "         0.1686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.1333, 0.2078, 0.2157, 0.6745, 0.2941,\n",
       "         0.1059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0039, 0.0000, 0.0078, 0.3333, 0.2980, 0.2941, 0.2039,\n",
       "         0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0039, 0.0039, 0.0000, 0.2196, 0.5020, 0.0157, 0.0706,\n",
       "         0.3451, 0.3216, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.4863, 0.3843, 0.1804,\n",
       "         0.6235, 0.7882, 0.6000, 0.1569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.4431, 0.4196,\n",
       "         0.5882, 0.5020, 0.1020, 0.2235, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.4078, 0.4314,\n",
       "         0.7137, 0.1843, 0.2196, 0.4118, 0.3216, 0.0196, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2549, 0.5647,\n",
       "         0.6275, 0.0824, 0.0000, 0.0000, 0.5098, 0.3333, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0039, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.5647,\n",
       "         0.5529, 0.0000, 0.0000, 0.0000, 0.0000, 0.6510, 0.3059, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922, 0.7216,\n",
       "         0.4510, 0.0000, 0.0000, 0.0157, 0.0000, 0.0000, 0.6275, 0.2667, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0784, 0.0784,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6392,\n",
       "         0.3804, 0.0000, 0.0000, 0.0000, 0.0314, 0.0000, 0.0000, 0.6667, 0.1529,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0314, 0.2471, 0.2980,\n",
       "         0.1686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5255,\n",
       "         0.5333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.6784,\n",
       "         0.0706, 0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.0000, 0.0706, 0.0941,\n",
       "         0.0000, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3451,\n",
       "         0.7137, 0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.6588, 0.0039, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078,\n",
       "         0.1922, 0.1059, 0.1216, 0.2196, 0.0667, 0.0000, 0.0000, 0.0000, 0.3451,\n",
       "         0.6000, 0.1922, 0.0000, 0.0196, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.6471, 0.0000, 0.0000, 0.0039, 0.0510, 0.0275, 0.0000, 0.0000,\n",
       "         0.0000, 0.3294, 0.3804, 0.4000, 0.4941, 0.3882, 0.0000, 0.0196, 0.5020,\n",
       "         0.6000, 0.2863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0039, 0.5451, 0.0000, 0.0000, 0.0000, 0.3176, 0.5961, 0.5725,\n",
       "         0.5490, 0.4863, 0.4824, 0.5098, 0.4941, 0.4431, 0.4431, 0.4471, 0.7216,\n",
       "         0.6235, 0.1647, 0.0000, 0.0000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.7294, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000,\n",
       "         0.0000, 0.0941, 0.1647, 0.1804, 0.2235, 0.2549, 0.2706, 0.2549, 0.2471,\n",
       "         0.1569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.7137, 0.0157, 0.0000, 0.0039, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_shape: int,\n",
    "                 hidden_units: int, \n",
    "                 output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape,\n",
    "                      out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "            return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV0(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_0 = FashionMNISTModelV0(\n",
    "    input_shape=28*28,\n",
    "    hidden_units=10,\n",
    "    output_shape=10\n",
    ").to(\"cpu\")\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_x = torch.rand([1, 1, 28, 28]) # batch, color channels, heigth, width\n",
    "model_0(dummy_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layer_stack.1.weight',\n",
       "              tensor([[ 0.0273,  0.0296, -0.0084,  ..., -0.0142,  0.0093,  0.0135],\n",
       "                      [-0.0188, -0.0354,  0.0187,  ..., -0.0106, -0.0001,  0.0115],\n",
       "                      [-0.0008,  0.0017,  0.0045,  ..., -0.0127, -0.0188,  0.0059],\n",
       "                      ...,\n",
       "                      [-0.0116,  0.0273, -0.0344,  ...,  0.0176,  0.0283, -0.0011],\n",
       "                      [-0.0230,  0.0257,  0.0291,  ..., -0.0187, -0.0087,  0.0001],\n",
       "                      [ 0.0176, -0.0147,  0.0053,  ..., -0.0336, -0.0221,  0.0205]])),\n",
       "             ('layer_stack.1.bias',\n",
       "              tensor([-0.0093,  0.0283, -0.0033,  0.0255,  0.0017,  0.0037, -0.0302, -0.0123,\n",
       "                       0.0018,  0.0163])),\n",
       "             ('layer_stack.2.weight',\n",
       "              tensor([[ 0.0614, -0.0687,  0.0021,  0.2718,  0.2109,  0.1079, -0.2279, -0.1063,\n",
       "                        0.2019,  0.2847],\n",
       "                      [-0.1495,  0.1344, -0.0740,  0.2006, -0.0475, -0.2514, -0.3130, -0.0118,\n",
       "                        0.0932, -0.1864],\n",
       "                      [ 0.2488,  0.1500,  0.1907,  0.1457, -0.3050, -0.0580,  0.1643,  0.1565,\n",
       "                       -0.2877, -0.1792],\n",
       "                      [ 0.2305, -0.2618,  0.2397, -0.0610,  0.0232,  0.1542,  0.0851, -0.2027,\n",
       "                        0.1030, -0.2715],\n",
       "                      [-0.1596, -0.0555, -0.0633,  0.2302, -0.1726,  0.2654,  0.1473,  0.1029,\n",
       "                        0.2252, -0.2160],\n",
       "                      [-0.2725,  0.0118,  0.1559,  0.1596,  0.0132,  0.3024,  0.1124,  0.1366,\n",
       "                       -0.1533,  0.0965],\n",
       "                      [-0.1184, -0.2555, -0.2057, -0.1909, -0.0477, -0.1324,  0.2905,  0.1307,\n",
       "                       -0.2629,  0.0133],\n",
       "                      [ 0.2727, -0.0127,  0.0513,  0.0863, -0.1043, -0.2047, -0.1185, -0.0825,\n",
       "                        0.2488, -0.2571],\n",
       "                      [ 0.0425, -0.1209, -0.0336, -0.0281, -0.1227,  0.0730,  0.0747, -0.1816,\n",
       "                        0.1943,  0.2853],\n",
       "                      [-0.1310,  0.0645, -0.1171,  0.2168, -0.0245, -0.2820,  0.0736,  0.2621,\n",
       "                        0.0012, -0.0810]])),\n",
       "             ('layer_stack.2.bias',\n",
       "              tensor([-0.0087,  0.1791,  0.2712, -0.0791,  0.1685,  0.1762,  0.2825,  0.2266,\n",
       "                      -0.2612, -0.2613]))])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions.py already exists, skipping download...\n"
     ]
    }
   ],
   "source": [
    "### 3.1 setup loss, optimizer & eval metrix\n",
    "\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "#Download helper functions \n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "    print(\"Helper functions.py already exists, skipping download...\")\n",
    "else:\n",
    "    print(\"Downloading helper_functions.py\")\n",
    "    request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "    with open(\"helper_functions.py\", \"wb\") as f:\n",
    "        f.write(request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import accuracy metric \n",
    "\n",
    "from helper_functions import accuracy_fn\n",
    "\n",
    "#setup loss function & optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
    "                            lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.2 create functions to time experiments\n",
    "from timeit import default_timer as timer\n",
    "def print_train_time(start: float,\n",
    "                     end: float,\n",
    "                     device: torch.device = None):\n",
    "    \"\"\" Prints difference between start and end.   \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time on cpu: 0.000 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7700000171316788e-05"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = timer()\n",
    "end_time = timer()\n",
    "print_train_time(start=start_time, end=end_time, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \n",
      "------\n",
      " Looked at 0/60000\n",
      " Looked at 12800/60000\n",
      " Looked at 25600/60000\n",
      " Looked at 38400/60000\n",
      " Looked at 51200/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:08<00:17,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Train loss: 0.5904 Test loss: 0.5095, Test acc: 82.0387\n",
      "Epoch: 1 \n",
      "------\n",
      " Looked at 0/60000\n",
      " Looked at 12800/60000\n",
      " Looked at 25600/60000\n",
      " Looked at 38400/60000\n",
      " Looked at 51200/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:16<00:08,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Train loss: 0.4763 Test loss: 0.4799, Test acc: 83.1969\n",
      "Epoch: 2 \n",
      "------\n",
      " Looked at 0/60000\n",
      " Looked at 12800/60000\n",
      " Looked at 25600/60000\n",
      " Looked at 38400/60000\n",
      " Looked at 51200/60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Train loss: 0.4550 Test loss: 0.4766, Test acc: 83.4265\n",
      "Train time on cpu: 23.720 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Creating training loop & testing loop\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "#set the seed\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "#Set the number of epochs\n",
    "epochs = 3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch} \\n------\")\n",
    "    ## Training \n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model_0.train()\n",
    "        #1 forward pass\n",
    "        y_pred = model_0(X)\n",
    "\n",
    "        #2. calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss +=loss\n",
    "\n",
    "        #3. optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #4. Loss Backward\n",
    "        loss.backward()\n",
    "\n",
    "        #5. optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        #print out whats happening\n",
    "        if batch % 400 == 0:\n",
    "            print(f\" Looked at {batch * len(X)}/{len(train_dataloader.dataset)}\")\n",
    "    #Divide total train loss by length of train data loader\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    ### Testing \n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dataloader:\n",
    "            #Forward pass\n",
    "            test_pred = model_0(X_test)\n",
    "\n",
    "            #2. loss calculation\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "            #3. cal accuracy \n",
    "            test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
    "        #Cal test loss avg per batch\n",
    "        test_loss /= len(test_dataloader)\n",
    "\n",
    "        #Cal test acc avg per batch\n",
    "        test_acc  /= len(test_dataloader)\n",
    "    # Print out what's happening \n",
    "    print(f\" \\n Train loss: {train_loss:.4f} Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")\n",
    "\n",
    "#calculate training time \n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
    "                                            end=train_time_end_on_cpu,\n",
    "                                            device=str(next(model_0.parameters()).device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Make predictions & get Model 0 results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model_name': 'FashionMNISTModelV0',\n",
       " 'model_loss': 0.47663888335227966,\n",
       " 'model_acc': 83.42651757188499}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "def eval_model(model: torch.nn.Module, \n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module, \n",
    "               accuracy_fn,\n",
    "               device=device):\n",
    "    \"\"\" Returns a dictionary containing the results of model predicting on data_loader.\"\"\"\n",
    "    loss, acc = 0, 0 \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            #Make Predictions \n",
    "            y_pred = model(X)\n",
    "\n",
    "            #Accumulate the loss and acc values per batch \n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y,\n",
    "                               y_pred=y_pred.argmax(dim=1))\n",
    "            \n",
    "        #Scale loss & acc \n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "    return {\"Model_name\": model.__class__.__name__,\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "\n",
    "#Calculate model 1 results on test dataset\n",
    "model_0_results = eval_model(model=model_0,\n",
    "                             data_loader=test_dataloader,\n",
    "                             loss_fn=loss_fn,\n",
    "                             accuracy_fn=accuracy_fn,\n",
    "                             device=device)\n",
    "model_0_results        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Setup device agnostic-code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setup device-gnostic code\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "#Model with linear & non-linear \n",
    "import torch\n",
    "from torch import nn\n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape,\n",
    "                      out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units,\n",
    "                      out_features=output_shape),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layer_stack(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_1 = FashionMNISTModelV1(input_shape=784,\n",
    "                              hidden_units=10,\n",
    "                              output_shape=10).to(device)\n",
    "next(model_1.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 setup loss fn & eval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
    "                            lr=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2 Functionizing training & eval/testing loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    \"\"\" Performs a training with model trying to learn on data_loader.\"\"\"\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "    #put model to training mode \n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        \n",
    "        #Put data on target device \n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        #1 forward pass \n",
    "        y_pred = model(X)\n",
    "\n",
    "        #2. calculate loss & accuracy\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss +=loss\n",
    "        train_acc += accuracy_fn(y_true=y,\n",
    "                                 y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        #3. optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #4. Loss Backward\n",
    "        loss.backward()\n",
    "\n",
    "        #5. optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    #Divide total train loss & accuracy by length of train data loader\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    \"\"\" Performs a testing loop step on model going over data_loader\"\"\"\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    #Put the model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    #Turn on Inference Mode context manager \n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            #send to device \n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            #1.Forward pass (Outputs raw logits)\n",
    "            test_pred = model(X)\n",
    "\n",
    "            #2. Calculate loss/acc\n",
    "            test_loss += loss_fn(test_pred, y) \n",
    "            test_acc += accuracy_fn(y_true=y,\n",
    "                                    y_pred=test_pred.argmax(dim=1)) # go from logits -> prediction labels\n",
    "            \n",
    "        #Adjust metrics and print out\n",
    "        test_loss /= len(data_loader)   \n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\" Test loss: {test_loss:.5f} | Test acc: {test_acc:.5f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 0 \n",
      "-------------\n",
      "Train loss: 1.09199 | Train acc: 61.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:07<00:15,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test loss: 0.95636 | Test acc: 64.99601%\n",
      "\n",
      "Epochs: 1 \n",
      "-------------\n",
      "Train loss: 0.78101 | Train acc: 71.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:15<00:07,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test loss: 0.72227 | Test acc: 73.91174%\n",
      "\n",
      "Epochs: 2 \n",
      "-------------\n",
      "Train loss: 0.67027 | Train acc: 75.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:23<00:00,  7.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test loss: 0.68500 | Test acc: 75.01997%\n",
      "\n",
      "Train time on cpu: 23.131 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "#Measure time \n",
    "from timeit import default_timer as Timer\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "#Set epochs\n",
    "epochs = 3\n",
    "\n",
    "#Create optimization & eval loop using train_step & test_step\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epochs: {epoch} \\n-------------\")\n",
    "    train_step(model=model_1,\n",
    "               data_loader=train_dataloader,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               accuracy_fn=accuracy_fn,\n",
    "               device=device)\n",
    "    test_step(model=model_1,\n",
    "              data_loader=test_dataloader,\n",
    "              loss_fn=loss_fn,\n",
    "              accuracy_fn=accuracy_fn,\n",
    "              device=device)\n",
    "\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_1 = print_train_time(start=train_time_start_on_cpu,\n",
    "                                            end=train_time_end_on_cpu,\n",
    "                                             device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model_name': 'FashionMNISTModelV0',\n",
       " 'model_loss': 0.47663888335227966,\n",
       " 'model_acc': 83.42651757188499}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.720409600000494"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_train_time_model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model_name': 'FashionMNISTModelV1',\n",
       " 'model_loss': 0.6850009560585022,\n",
       " 'model_acc': 75.01996805111821}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get model 1 results dictionary \n",
    "model_1_results = eval_model(model=model_1,\n",
    "                             data_loader=test_dataloader,\n",
    "                             loss_fn=loss_fn,\n",
    "                             accuracy_fn=accuracy_fn,\n",
    "                             device=device)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Model 2: Building CNN \n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture replicates the TinyVGG\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1), # Values we can set ourselves in our NN's are called hyperparameters\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*0,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "        \n",
    "def forward(self, x):\n",
    "    x = self.conv_block_1(x)\n",
    "    print(x.shape)\n",
    "    x = self.conv_block_2(x)\n",
    "    print(x.shape)\n",
    "    x = self.classifier(x)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv_block_1.0.weight',\n",
       "              tensor([[[[ 0.2548,  0.2767, -0.0781],\n",
       "                        [ 0.3062, -0.0730,  0.0673],\n",
       "                        [-0.1623,  0.1958,  0.2938]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2445,  0.2897,  0.0624],\n",
       "                        [ 0.2463,  0.0451,  0.1607],\n",
       "                        [-0.0471,  0.2570,  0.0493]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1556,  0.0850, -0.1536],\n",
       "                        [-0.0391, -0.1354,  0.2211],\n",
       "                        [-0.2631, -0.1537, -0.0941]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2004,  0.0315, -0.3292],\n",
       "                        [ 0.3010, -0.2832,  0.2573],\n",
       "                        [ 0.0555, -0.1082,  0.2060]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0520,  0.2693,  0.0364],\n",
       "                        [-0.1051,  0.0896, -0.0904],\n",
       "                        [ 0.1403,  0.2976,  0.1927]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1457,  0.1924,  0.0596],\n",
       "                        [ 0.1693, -0.2032, -0.3300],\n",
       "                        [-0.1288, -0.2557,  0.2735]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0960,  0.1381,  0.1054],\n",
       "                        [-0.0058,  0.2609, -0.2368],\n",
       "                        [ 0.0210, -0.2275,  0.1028]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1148,  0.1021, -0.0694],\n",
       "                        [ 0.2765, -0.1976, -0.1988],\n",
       "                        [-0.1988,  0.2998,  0.1111]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3208, -0.2751, -0.3306],\n",
       "                        [-0.2608, -0.2242,  0.1350],\n",
       "                        [ 0.1194,  0.2770, -0.1721]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2272,  0.1769, -0.1347],\n",
       "                        [ 0.2023, -0.0791,  0.1907],\n",
       "                        [-0.2590, -0.1682,  0.1016]]]])),\n",
       "             ('conv_block_1.0.bias',\n",
       "              tensor([ 0.0705, -0.0850,  0.1987,  0.2266, -0.2417, -0.1780,  0.3052, -0.1125,\n",
       "                      -0.1182, -0.3225])),\n",
       "             ('conv_block_1.2.weight',\n",
       "              tensor([[[[-0.0604,  0.0263, -0.0139],\n",
       "                        [-0.0765,  0.0025, -0.0720],\n",
       "                        [-0.0894, -0.0580, -0.0923]],\n",
       "              \n",
       "                       [[-0.0671,  0.1054,  0.0199],\n",
       "                        [ 0.0325, -0.0983, -0.0692],\n",
       "                        [-0.0351,  0.0165, -0.0928]],\n",
       "              \n",
       "                       [[-0.0454, -0.0631,  0.0003],\n",
       "                        [-0.0392, -0.0073, -0.0714],\n",
       "                        [-0.0724, -0.0615, -0.0361]],\n",
       "              \n",
       "                       [[-0.0832,  0.0884, -0.0209],\n",
       "                        [ 0.0907,  0.0328, -0.0893],\n",
       "                        [ 0.0729, -0.0290, -0.0404]],\n",
       "              \n",
       "                       [[-0.0875, -0.1048,  0.0302],\n",
       "                        [-0.0230,  0.0410, -0.0865],\n",
       "                        [ 0.0783, -0.0774, -0.0182]],\n",
       "              \n",
       "                       [[ 0.0220,  0.0544,  0.0851],\n",
       "                        [ 0.0960, -0.0836,  0.0265],\n",
       "                        [-0.0453, -0.0116, -0.0789]],\n",
       "              \n",
       "                       [[ 0.0960, -0.0774,  0.0563],\n",
       "                        [ 0.0370,  0.0343, -0.0570],\n",
       "                        [ 0.0958,  0.0232,  0.0136]],\n",
       "              \n",
       "                       [[-0.0929,  0.0442, -0.0158],\n",
       "                        [-0.0483,  0.0905,  0.0235],\n",
       "                        [-0.0583, -0.0534, -0.0050]],\n",
       "              \n",
       "                       [[ 0.0589, -0.0269, -0.0601],\n",
       "                        [-0.0361, -0.0787,  0.0376],\n",
       "                        [ 0.0816, -0.0992,  0.0245]],\n",
       "              \n",
       "                       [[ 0.0545,  0.0191, -0.0375],\n",
       "                        [ 0.0550,  0.0554,  0.0394],\n",
       "                        [-0.0185, -0.0279,  0.0113]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0186, -0.0314,  0.0674],\n",
       "                        [ 0.0906, -0.0104, -0.0236],\n",
       "                        [ 0.0015, -0.0063,  0.0253]],\n",
       "              \n",
       "                       [[ 0.0295, -0.0957, -0.0389],\n",
       "                        [ 0.0888,  0.0411, -0.0052],\n",
       "                        [-0.0636, -0.0645, -0.0944]],\n",
       "              \n",
       "                       [[-0.0344,  0.0356,  0.0672],\n",
       "                        [ 0.0487, -0.0932, -0.0634],\n",
       "                        [-0.0166,  0.1020,  0.0152]],\n",
       "              \n",
       "                       [[-0.0273,  0.0436, -0.0401],\n",
       "                        [-0.0682,  0.0769, -0.0479],\n",
       "                        [-0.0211, -0.1049,  0.0705]],\n",
       "              \n",
       "                       [[ 0.0799,  0.0384, -0.0735],\n",
       "                        [-0.1040, -0.0856,  0.0786],\n",
       "                        [ 0.0506,  0.0887,  0.0552]],\n",
       "              \n",
       "                       [[ 0.0267, -0.0010, -0.0802],\n",
       "                        [-0.0903, -0.0986,  0.0432],\n",
       "                        [-0.0518, -0.0212, -0.0607]],\n",
       "              \n",
       "                       [[-0.0192, -0.0742, -0.0689],\n",
       "                        [ 0.0350, -0.0313,  0.0651],\n",
       "                        [-0.0338, -0.0773, -0.0186]],\n",
       "              \n",
       "                       [[-0.0511, -0.0322, -0.1003],\n",
       "                        [ 0.0590, -0.0734,  0.0530],\n",
       "                        [ 0.0478,  0.0753, -0.0809]],\n",
       "              \n",
       "                       [[ 0.0758, -0.0498,  0.0391],\n",
       "                        [ 0.0990, -0.0149, -0.0008],\n",
       "                        [-0.0243, -0.0880,  0.0506]],\n",
       "              \n",
       "                       [[-0.1046,  0.0654,  0.0789],\n",
       "                        [ 0.0997, -0.0249, -0.0866],\n",
       "                        [ 0.0237,  0.0582, -0.1049]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0239, -0.0632, -0.0092],\n",
       "                        [-0.0519, -0.0431, -0.0335],\n",
       "                        [-0.1002,  0.0865,  0.0884]],\n",
       "              \n",
       "                       [[-0.0165, -0.0120, -0.0430],\n",
       "                        [-0.0952, -0.1026,  0.0392],\n",
       "                        [-0.0579, -0.0678, -0.0082]],\n",
       "              \n",
       "                       [[-0.0351, -0.0341,  0.0034],\n",
       "                        [-0.0224, -0.0363, -0.0505],\n",
       "                        [-0.0858,  0.0884, -0.0422]],\n",
       "              \n",
       "                       [[ 0.0279, -0.0366,  0.0086],\n",
       "                        [ 0.0983,  0.0486, -0.0913],\n",
       "                        [ 0.0418,  0.1001,  0.0277]],\n",
       "              \n",
       "                       [[ 0.0707,  0.1039, -0.0162],\n",
       "                        [ 0.0219, -0.0733, -0.0217],\n",
       "                        [ 0.0781,  0.0540, -0.0667]],\n",
       "              \n",
       "                       [[-0.0845, -0.0720, -0.1040],\n",
       "                        [-0.0813, -0.0261,  0.0711],\n",
       "                        [ 0.0176, -0.0802, -0.0846]],\n",
       "              \n",
       "                       [[ 0.0524, -0.0784, -0.0130],\n",
       "                        [ 0.0506, -0.0488, -0.0115],\n",
       "                        [-0.0092, -0.0249, -0.0534]],\n",
       "              \n",
       "                       [[-0.0940, -0.0852, -0.0564],\n",
       "                        [ 0.1018, -0.0509, -0.0708],\n",
       "                        [ 0.0256,  0.0291,  0.0578]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0587, -0.1045],\n",
       "                        [ 0.0093,  0.0639, -0.0097],\n",
       "                        [-0.0621,  0.1005, -0.0394]],\n",
       "              \n",
       "                       [[-0.0600, -0.0950,  0.0047],\n",
       "                        [ 0.0467,  0.0233,  0.0208],\n",
       "                        [-0.0799, -0.0984,  0.0019]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0961,  0.0608, -0.0614],\n",
       "                        [-0.0137, -0.0777, -0.0509],\n",
       "                        [ 0.0191,  0.0574,  0.0873]],\n",
       "              \n",
       "                       [[-0.0968,  0.0705, -0.0743],\n",
       "                        [ 0.0395,  0.0892,  0.0015],\n",
       "                        [ 0.0959, -0.0898, -0.0403]],\n",
       "              \n",
       "                       [[ 0.0615, -0.0230, -0.0216],\n",
       "                        [-0.0439,  0.0727,  0.0517],\n",
       "                        [ 0.0338, -0.0592, -0.0856]],\n",
       "              \n",
       "                       [[ 0.0114,  0.0312, -0.0487],\n",
       "                        [-0.0295,  0.0712,  0.0084],\n",
       "                        [ 0.0048, -0.0259, -0.0955]],\n",
       "              \n",
       "                       [[-0.0991, -0.0504, -0.0536],\n",
       "                        [ 0.0328, -0.0307, -0.0412],\n",
       "                        [ 0.1005,  0.0367,  0.0751]],\n",
       "              \n",
       "                       [[-0.0510, -0.0431,  0.0387],\n",
       "                        [-0.0702, -0.0689, -0.0051],\n",
       "                        [-0.0386, -0.0790,  0.0625]],\n",
       "              \n",
       "                       [[ 0.0848,  0.0171, -0.0184],\n",
       "                        [-0.0976, -0.0384,  0.0268],\n",
       "                        [ 0.0497, -0.0133, -0.0417]],\n",
       "              \n",
       "                       [[ 0.0587, -0.0839,  0.0666],\n",
       "                        [-0.0409,  0.0016, -0.0208],\n",
       "                        [ 0.0128, -0.0319,  0.0766]],\n",
       "              \n",
       "                       [[-0.0027,  0.0823,  0.1013],\n",
       "                        [-0.0514, -0.0769,  0.0846],\n",
       "                        [ 0.0826, -0.0805, -0.0081]],\n",
       "              \n",
       "                       [[-0.1039, -0.0863,  0.0204],\n",
       "                        [ 0.0280,  0.0223, -0.0287],\n",
       "                        [ 0.0972,  0.0151, -0.0622]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0060,  0.0253,  0.0369],\n",
       "                        [-0.0745,  0.0395, -0.0539],\n",
       "                        [-0.0876, -0.0576,  0.1017]],\n",
       "              \n",
       "                       [[ 0.0901,  0.0944,  0.0619],\n",
       "                        [ 0.0796, -0.0141, -0.0580],\n",
       "                        [ 0.0527, -0.0546, -0.0711]],\n",
       "              \n",
       "                       [[-0.0337,  0.0221,  0.0543],\n",
       "                        [-0.0409, -0.0620,  0.0142],\n",
       "                        [-0.0621, -0.0686,  0.0549]],\n",
       "              \n",
       "                       [[-0.0177,  0.0963,  0.1025],\n",
       "                        [ 0.0315,  0.0363,  0.0243],\n",
       "                        [ 0.0017, -0.0077,  0.0014]],\n",
       "              \n",
       "                       [[ 0.0394,  0.0980, -0.0273],\n",
       "                        [-0.0446, -0.0255, -0.0509],\n",
       "                        [ 0.0179,  0.0787,  0.0824]],\n",
       "              \n",
       "                       [[ 0.0484, -0.0776, -0.0566],\n",
       "                        [-0.0232, -0.0194,  0.0087],\n",
       "                        [-0.0968,  0.0328, -0.0804]],\n",
       "              \n",
       "                       [[-0.0667, -0.0876,  0.0918],\n",
       "                        [-0.0998,  0.0795, -0.0035],\n",
       "                        [-0.0123,  0.0659, -0.0097]],\n",
       "              \n",
       "                       [[ 0.0661,  0.0762, -0.0915],\n",
       "                        [ 0.0406,  0.0199,  0.0227],\n",
       "                        [ 0.0154,  0.0288, -0.0507]],\n",
       "              \n",
       "                       [[-0.0135,  0.1002,  0.0708],\n",
       "                        [-0.0040, -0.0991,  0.0046],\n",
       "                        [-0.0718,  0.0857, -0.0640]],\n",
       "              \n",
       "                       [[-0.0076, -0.0234,  0.0188],\n",
       "                        [ 0.0992,  0.0100,  0.0610],\n",
       "                        [ 0.0818,  0.0851, -0.0364]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0236,  0.0508, -0.0288],\n",
       "                        [ 0.0494, -0.0230, -0.0715],\n",
       "                        [ 0.0429,  0.0162,  0.0470]],\n",
       "              \n",
       "                       [[ 0.1047,  0.0720,  0.0999],\n",
       "                        [ 0.0056, -0.0907, -0.0739],\n",
       "                        [-0.0655, -0.0929, -0.0528]],\n",
       "              \n",
       "                       [[-0.0970, -0.0973, -0.0630],\n",
       "                        [-0.1039, -0.0647,  0.0402],\n",
       "                        [ 0.0879, -0.0314, -0.0307]],\n",
       "              \n",
       "                       [[ 0.0563, -0.0520, -0.0498],\n",
       "                        [ 0.0649, -0.0918,  0.0129],\n",
       "                        [ 0.0931,  0.0181,  0.0287]],\n",
       "              \n",
       "                       [[-0.0614, -0.0015,  0.0058],\n",
       "                        [ 0.0259,  0.0410,  0.0916],\n",
       "                        [-0.0805,  0.0032, -0.0527]],\n",
       "              \n",
       "                       [[-0.0834, -0.0084, -0.0928],\n",
       "                        [ 0.0736,  0.0122, -0.0568],\n",
       "                        [ 0.0551, -0.0998, -0.0408]],\n",
       "              \n",
       "                       [[-0.0205, -0.0896, -0.0670],\n",
       "                        [-0.0172,  0.0800,  0.1018],\n",
       "                        [ 0.0671, -0.0629, -0.0690]],\n",
       "              \n",
       "                       [[ 0.0920,  0.0373,  0.0028],\n",
       "                        [ 0.0143, -0.0847, -0.0352],\n",
       "                        [ 0.1015, -0.0260, -0.0053]],\n",
       "              \n",
       "                       [[-0.0875, -0.0590, -0.0022],\n",
       "                        [-0.0655, -0.0131,  0.0429],\n",
       "                        [-0.1031,  0.0313, -0.0697]],\n",
       "              \n",
       "                       [[-0.0514,  0.0405,  0.0838],\n",
       "                        [-0.0288, -0.0433, -0.0953],\n",
       "                        [-0.0544, -0.0923, -0.0241]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0215, -0.0988,  0.0920],\n",
       "                        [ 0.0661, -0.1032, -0.0503],\n",
       "                        [ 0.0344, -0.0217, -0.0115]],\n",
       "              \n",
       "                       [[-0.0476,  0.0847, -0.0589],\n",
       "                        [ 0.0874,  0.0068,  0.0212],\n",
       "                        [ 0.0822, -0.0174, -0.0600]],\n",
       "              \n",
       "                       [[-0.0170,  0.0855, -0.0782],\n",
       "                        [ 0.0239, -0.1036,  0.0553],\n",
       "                        [ 0.0389,  0.0045,  0.0452]],\n",
       "              \n",
       "                       [[ 0.0001,  0.0583, -0.0834],\n",
       "                        [-0.0155,  0.0468,  0.1050],\n",
       "                        [ 0.0537, -0.0767,  0.0811]],\n",
       "              \n",
       "                       [[-0.0235, -0.0225, -0.0958],\n",
       "                        [-0.0166,  0.0746,  0.0147],\n",
       "                        [-0.0614,  0.0324, -0.0338]],\n",
       "              \n",
       "                       [[ 0.0962, -0.0915, -0.0333],\n",
       "                        [-0.1018, -0.0415,  0.0332],\n",
       "                        [ 0.1015,  0.0177,  0.1033]],\n",
       "              \n",
       "                       [[ 0.0206,  0.0609,  0.0845],\n",
       "                        [ 0.0881, -0.0590,  0.0969],\n",
       "                        [ 0.0639, -0.0493, -0.0503]],\n",
       "              \n",
       "                       [[-0.0884,  0.0265, -0.0854],\n",
       "                        [ 0.0445,  0.0333, -0.0916],\n",
       "                        [ 0.0287, -0.0086,  0.0482]],\n",
       "              \n",
       "                       [[ 0.0605, -0.1048,  0.0967],\n",
       "                        [ 0.0884,  0.0419, -0.0963],\n",
       "                        [-0.0377, -0.0305, -0.0271]],\n",
       "              \n",
       "                       [[ 0.0594,  0.0383,  0.0835],\n",
       "                        [-0.0395,  0.0355,  0.0375],\n",
       "                        [-0.0878, -0.1022, -0.0547]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0722, -0.0992, -0.0918],\n",
       "                        [ 0.0591,  0.0569,  0.0867],\n",
       "                        [-0.0796, -0.0771,  0.0541]],\n",
       "              \n",
       "                       [[ 0.0917,  0.0631,  0.0165],\n",
       "                        [ 0.0347,  0.1000, -0.0680],\n",
       "                        [-0.0479,  0.0737, -0.0721]],\n",
       "              \n",
       "                       [[-0.0581,  0.0769,  0.0333],\n",
       "                        [ 0.0341, -0.0447, -0.0015],\n",
       "                        [ 0.0965, -0.0633,  0.0008]],\n",
       "              \n",
       "                       [[ 0.0501, -0.0728,  0.1024],\n",
       "                        [-0.0527, -0.0253, -0.0285],\n",
       "                        [-0.0687, -0.1034,  0.0594]],\n",
       "              \n",
       "                       [[ 0.0280, -0.0987, -0.0678],\n",
       "                        [ 0.1042,  0.0403,  0.0423],\n",
       "                        [-0.0631, -0.0462, -0.0159]],\n",
       "              \n",
       "                       [[-0.0193, -0.0722,  0.0087],\n",
       "                        [ 0.0105, -0.0133,  0.0146],\n",
       "                        [-0.0418,  0.0274,  0.0398]],\n",
       "              \n",
       "                       [[-0.0555, -0.1045,  0.0552],\n",
       "                        [ 0.0251, -0.0536,  0.1016],\n",
       "                        [-0.0477,  0.0712,  0.0535]],\n",
       "              \n",
       "                       [[-0.0884,  0.0680, -0.0969],\n",
       "                        [-0.0584, -0.0176, -0.0711],\n",
       "                        [ 0.1030, -0.0211,  0.0419]],\n",
       "              \n",
       "                       [[-0.0941,  0.0607, -0.0328],\n",
       "                        [-0.0802,  0.0154,  0.0511],\n",
       "                        [ 0.0912, -0.0644, -0.0519]],\n",
       "              \n",
       "                       [[ 0.0203,  0.0286,  0.0405],\n",
       "                        [ 0.0579, -0.0239,  0.0586],\n",
       "                        [ 0.0777, -0.0275,  0.0750]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0515,  0.0930, -0.0599],\n",
       "                        [-0.0521, -0.0305,  0.0053],\n",
       "                        [ 0.0633, -0.0602,  0.0528]],\n",
       "              \n",
       "                       [[-0.0378,  0.0637, -0.0050],\n",
       "                        [-0.0923, -0.0580, -0.0763],\n",
       "                        [ 0.0523, -0.0707, -0.0088]],\n",
       "              \n",
       "                       [[ 0.0227, -0.0578,  0.0304],\n",
       "                        [-0.1029, -0.0754, -0.0955],\n",
       "                        [-0.0319, -0.0384,  0.0151]],\n",
       "              \n",
       "                       [[-0.0195,  0.0496,  0.0966],\n",
       "                        [ 0.0378, -0.0415, -0.0987],\n",
       "                        [ 0.0382, -0.0522,  0.0536]],\n",
       "              \n",
       "                       [[ 0.0705,  0.0407,  0.0989],\n",
       "                        [ 0.1001,  0.0223, -0.0768],\n",
       "                        [ 0.0942, -0.0500, -0.0498]],\n",
       "              \n",
       "                       [[ 0.0882,  0.0817,  0.0318],\n",
       "                        [ 0.0066, -0.0887, -0.0109],\n",
       "                        [ 0.1011,  0.0268,  0.0090]],\n",
       "              \n",
       "                       [[-0.0219, -0.0368,  0.0628],\n",
       "                        [ 0.0065,  0.0686, -0.0187],\n",
       "                        [ 0.0461,  0.0435,  0.0168]],\n",
       "              \n",
       "                       [[ 0.0662,  0.0661,  0.0977],\n",
       "                        [ 0.0810, -0.0270, -0.0892],\n",
       "                        [ 0.0193, -0.0009, -0.0275]],\n",
       "              \n",
       "                       [[-0.0177,  0.0050,  0.0769],\n",
       "                        [ 0.0329, -0.0374, -0.0433],\n",
       "                        [-0.0261, -0.0407,  0.0948]],\n",
       "              \n",
       "                       [[ 0.0558,  0.0952,  0.0003],\n",
       "                        [ 0.0213,  0.0366, -0.0998],\n",
       "                        [ 0.0094, -0.0071, -0.0591]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0818,  0.0933,  0.0857],\n",
       "                        [ 0.0489,  0.1006, -0.0428],\n",
       "                        [-0.0182,  0.0399, -0.0174]],\n",
       "              \n",
       "                       [[-0.0207, -0.0871,  0.0283],\n",
       "                        [-0.0637,  0.0038,  0.1028],\n",
       "                        [-0.0324, -0.0332,  0.0636]],\n",
       "              \n",
       "                       [[-0.0388, -0.0091,  0.0984],\n",
       "                        [-0.0432, -0.0754, -0.0590],\n",
       "                        [-0.0292, -0.0500, -0.0547]],\n",
       "              \n",
       "                       [[ 0.0426,  0.0179, -0.0337],\n",
       "                        [-0.0819, -0.0332, -0.0445],\n",
       "                        [-0.0343, -0.0951,  0.0227]],\n",
       "              \n",
       "                       [[-0.0774, -0.0821, -0.0861],\n",
       "                        [ 0.0440, -0.0635, -0.0435],\n",
       "                        [ 0.0826,  0.0560,  0.0604]],\n",
       "              \n",
       "                       [[-0.1001, -0.0756, -0.0398],\n",
       "                        [ 0.0871,  0.0108, -0.0788],\n",
       "                        [ 0.0007, -0.0819, -0.0231]],\n",
       "              \n",
       "                       [[-0.0290,  0.0912,  0.0326],\n",
       "                        [-0.0184,  0.0178, -0.0304],\n",
       "                        [ 0.0414,  0.0417,  0.0283]],\n",
       "              \n",
       "                       [[-0.0411,  0.0899, -0.0152],\n",
       "                        [-0.0410,  0.0660,  0.0859],\n",
       "                        [ 0.1049,  0.0312, -0.0359]],\n",
       "              \n",
       "                       [[ 0.0535,  0.0904, -0.1034],\n",
       "                        [-0.0131, -0.0719,  0.0196],\n",
       "                        [ 0.0436, -0.0218, -0.0088]],\n",
       "              \n",
       "                       [[ 0.0474, -0.0177, -0.0885],\n",
       "                        [ 0.0843, -0.0531, -0.0116],\n",
       "                        [ 0.0099, -0.0063, -0.0992]]]])),\n",
       "             ('conv_block_1.2.bias',\n",
       "              tensor([ 0.0484, -0.0479, -0.0547,  0.0252, -0.0550, -0.0487, -0.0355, -0.0396,\n",
       "                      -0.0440, -0.0284])),\n",
       "             ('conv_block_2.0.weight',\n",
       "              tensor([[[[ 2.7393e-02, -8.5299e-02, -6.3802e-02],\n",
       "                        [ 1.5381e-03,  1.4659e-02,  5.8217e-02],\n",
       "                        [-7.4044e-02,  3.3646e-02,  5.9914e-02]],\n",
       "              \n",
       "                       [[ 5.8530e-02, -9.8180e-02, -4.0225e-02],\n",
       "                        [-9.0606e-02, -6.6704e-02,  5.8711e-02],\n",
       "                        [-1.5740e-02,  4.4769e-02, -6.1876e-02]],\n",
       "              \n",
       "                       [[ 1.6018e-02, -6.3758e-02,  5.2693e-02],\n",
       "                        [-4.6104e-02, -2.6432e-02, -9.1456e-02],\n",
       "                        [ 3.4823e-04,  1.0008e-01,  5.1163e-02]],\n",
       "              \n",
       "                       [[-5.6240e-02,  1.4176e-03, -1.1558e-02],\n",
       "                        [-8.4862e-02,  8.2650e-02,  1.6993e-03],\n",
       "                        [ 2.2199e-02, -4.2567e-02, -4.9323e-02]],\n",
       "              \n",
       "                       [[ 1.7381e-02,  3.8971e-02,  2.3643e-02],\n",
       "                        [-5.0801e-02,  1.0234e-01, -1.5517e-02],\n",
       "                        [-6.4554e-02, -4.9301e-02,  1.0377e-01]],\n",
       "              \n",
       "                       [[ 5.0738e-06, -1.4309e-02, -4.3867e-02],\n",
       "                        [-2.7633e-02, -8.8779e-02, -8.3767e-02],\n",
       "                        [ 6.1695e-02,  9.0172e-02,  1.0059e-01]],\n",
       "              \n",
       "                       [[-7.6099e-02,  5.7012e-02, -6.5245e-02],\n",
       "                        [ 6.2883e-02,  7.6058e-02,  8.1573e-02],\n",
       "                        [ 7.5900e-02,  6.5941e-02,  2.0517e-03]],\n",
       "              \n",
       "                       [[ 4.8434e-02, -3.7712e-02,  4.5899e-02],\n",
       "                        [-3.3879e-02, -1.7700e-03, -9.1746e-02],\n",
       "                        [-2.7562e-02, -5.5432e-02, -3.5557e-02]],\n",
       "              \n",
       "                       [[-6.7313e-02, -9.4810e-02,  6.8639e-03],\n",
       "                        [ 6.8408e-02,  9.6001e-02,  6.1512e-02],\n",
       "                        [-5.4638e-02, -1.0425e-01,  3.9983e-02]],\n",
       "              \n",
       "                       [[ 5.9062e-02, -9.0495e-02,  3.7798e-02],\n",
       "                        [ 8.9121e-02,  6.3853e-03, -6.3505e-02],\n",
       "                        [ 8.6423e-02,  4.5011e-02,  6.9802e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.1287e-02,  6.1342e-02, -7.2002e-02],\n",
       "                        [ 1.0430e-01, -4.4662e-02,  6.3516e-02],\n",
       "                        [ 2.1107e-02,  2.7935e-02, -1.6165e-02]],\n",
       "              \n",
       "                       [[ 4.3295e-02, -4.3932e-02, -9.9357e-02],\n",
       "                        [-4.0499e-02,  8.2592e-02, -2.7751e-02],\n",
       "                        [ 3.3132e-02, -3.8973e-02,  7.9073e-02]],\n",
       "              \n",
       "                       [[ 6.3086e-02,  3.7211e-02, -5.3881e-02],\n",
       "                        [-8.6133e-02,  3.9686e-03, -6.1839e-02],\n",
       "                        [ 8.6667e-02, -1.0130e-01,  4.7104e-02]],\n",
       "              \n",
       "                       [[ 1.0508e-01,  5.2792e-02,  3.5942e-02],\n",
       "                        [-1.0142e-01,  1.0139e-01, -1.8030e-02],\n",
       "                        [-9.8495e-02,  1.0406e-01, -4.2894e-02]],\n",
       "              \n",
       "                       [[-7.4575e-03,  9.6479e-02, -7.3070e-02],\n",
       "                        [-7.4576e-02,  1.7141e-02, -1.4109e-02],\n",
       "                        [ 2.4280e-02, -8.8407e-02,  3.1524e-03]],\n",
       "              \n",
       "                       [[-4.6882e-02, -5.1820e-02, -9.6517e-02],\n",
       "                        [ 5.5890e-02,  2.0306e-02, -8.9118e-02],\n",
       "                        [ 8.3648e-02,  3.1794e-02,  1.9560e-02]],\n",
       "              \n",
       "                       [[-6.1890e-02,  1.5896e-02,  1.0157e-01],\n",
       "                        [ 7.2299e-02, -8.2100e-02,  9.6220e-02],\n",
       "                        [ 8.1702e-03,  5.0698e-02,  8.1869e-02]],\n",
       "              \n",
       "                       [[ 8.9862e-02, -8.2170e-02,  9.2303e-02],\n",
       "                        [-7.1591e-02,  7.9021e-03, -7.3656e-02],\n",
       "                        [-2.3109e-02, -4.7901e-03, -1.2611e-02]],\n",
       "              \n",
       "                       [[-1.6652e-02,  8.3137e-03,  1.0398e-01],\n",
       "                        [ 6.1244e-02,  5.8973e-02,  4.2190e-02],\n",
       "                        [ 8.1606e-02, -4.8645e-03,  8.3813e-03]],\n",
       "              \n",
       "                       [[ 2.1693e-02, -9.1931e-02, -8.4913e-02],\n",
       "                        [ 1.2923e-02, -4.1241e-02, -1.9342e-03],\n",
       "                        [-2.4187e-02,  1.6408e-02,  6.8581e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4958e-02,  8.4418e-02,  8.3227e-02],\n",
       "                        [-8.0901e-02, -8.1400e-02, -8.5284e-02],\n",
       "                        [-5.7766e-02, -4.1033e-02, -7.9341e-03]],\n",
       "              \n",
       "                       [[-2.5635e-02, -5.3258e-02, -3.3488e-02],\n",
       "                        [-3.8131e-02,  1.0341e-01, -3.9068e-02],\n",
       "                        [-7.5473e-02,  4.3818e-02, -6.0886e-03]],\n",
       "              \n",
       "                       [[ 8.0698e-02,  6.5863e-02,  9.6843e-02],\n",
       "                        [-7.7197e-02,  6.7764e-02,  8.8464e-02],\n",
       "                        [-5.2054e-02,  9.6890e-02,  7.9019e-02]],\n",
       "              \n",
       "                       [[ 1.1544e-03,  5.0823e-02, -3.6853e-02],\n",
       "                        [-9.1936e-02,  2.6645e-02,  3.1425e-02],\n",
       "                        [-6.8891e-02,  5.1123e-02, -9.0043e-02]],\n",
       "              \n",
       "                       [[ 9.0718e-02,  1.0208e-01,  2.8699e-02],\n",
       "                        [-6.6137e-02,  5.1300e-02,  1.7963e-02],\n",
       "                        [ 2.8663e-02,  3.4643e-02,  8.0254e-02]],\n",
       "              \n",
       "                       [[-4.5309e-02, -2.3711e-02,  2.8746e-02],\n",
       "                        [ 1.1486e-02,  8.5000e-02, -5.5365e-02],\n",
       "                        [-3.8387e-03,  1.9696e-02, -2.7996e-02]],\n",
       "              \n",
       "                       [[ 7.1859e-02,  1.1530e-02, -9.7422e-02],\n",
       "                        [-1.1420e-02, -4.7809e-02,  1.0243e-02],\n",
       "                        [-1.2250e-02, -1.0456e-01, -1.9208e-02]],\n",
       "              \n",
       "                       [[-1.0096e-02, -3.1083e-02,  9.6848e-02],\n",
       "                        [-2.3000e-02,  6.7717e-02,  2.6112e-02],\n",
       "                        [-8.8979e-02,  2.4770e-02,  8.7356e-02]],\n",
       "              \n",
       "                       [[-6.8948e-02, -6.8134e-02,  1.0318e-01],\n",
       "                        [ 8.4697e-02, -5.8807e-02,  6.3429e-02],\n",
       "                        [-1.3485e-02, -1.0393e-01,  7.9198e-03]],\n",
       "              \n",
       "                       [[ 3.4057e-02, -3.1619e-02,  3.6670e-02],\n",
       "                        [-9.0136e-02,  7.3050e-02,  8.9865e-02],\n",
       "                        [ 5.8130e-02,  1.7866e-02,  3.4716e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.6269e-02, -2.6339e-02, -1.0063e-02],\n",
       "                        [-5.8659e-02, -7.7857e-02,  7.0900e-02],\n",
       "                        [ 7.1535e-02, -9.5731e-02,  3.3542e-02]],\n",
       "              \n",
       "                       [[ 4.2881e-02,  1.0014e-01,  6.0985e-02],\n",
       "                        [ 9.6907e-02, -3.4510e-02,  7.3827e-02],\n",
       "                        [ 8.5740e-02, -9.9541e-02, -8.4613e-02]],\n",
       "              \n",
       "                       [[ 2.1335e-02,  5.7557e-02, -5.2369e-02],\n",
       "                        [ 1.1609e-02, -1.5303e-04,  2.6680e-02],\n",
       "                        [-5.6642e-02,  5.9455e-02,  7.0098e-02]],\n",
       "              \n",
       "                       [[-7.3139e-02,  1.0211e-03,  2.9247e-04],\n",
       "                        [ 3.3849e-02,  9.8198e-02,  3.0913e-02],\n",
       "                        [-2.3951e-02,  9.4672e-02, -4.0112e-02]],\n",
       "              \n",
       "                       [[-3.0608e-02,  7.1969e-03, -8.0270e-02],\n",
       "                        [ 1.1470e-02, -7.1518e-02,  1.0838e-02],\n",
       "                        [ 1.0099e-02,  1.4591e-02, -8.8891e-02]],\n",
       "              \n",
       "                       [[-1.0012e-01,  4.8501e-02,  9.0399e-02],\n",
       "                        [-9.3537e-02,  3.9043e-02, -7.7594e-02],\n",
       "                        [ 6.6082e-03,  9.8068e-02,  7.9965e-02]],\n",
       "              \n",
       "                       [[-7.7069e-02,  6.5203e-02,  5.5057e-02],\n",
       "                        [-1.6169e-04,  1.0211e-01, -4.1866e-02],\n",
       "                        [-2.4530e-02, -5.3275e-02,  1.5168e-02]],\n",
       "              \n",
       "                       [[ 2.7911e-02,  8.3990e-03, -5.9307e-02],\n",
       "                        [-4.7452e-02,  3.5855e-02, -9.2426e-02],\n",
       "                        [-1.6416e-02, -2.3350e-03, -4.2708e-02]],\n",
       "              \n",
       "                       [[ 3.8360e-02,  6.7940e-03,  7.4004e-02],\n",
       "                        [-9.3616e-03, -6.6528e-02,  7.4477e-02],\n",
       "                        [ 1.4720e-02, -3.0189e-02, -6.9476e-02]],\n",
       "              \n",
       "                       [[ 2.4707e-02, -1.0053e-01,  2.7762e-02],\n",
       "                        [ 5.2119e-02, -9.2465e-02, -6.9009e-02],\n",
       "                        [-7.5781e-02,  8.8597e-02,  8.9611e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.5987e-03,  9.8959e-02, -3.5239e-02],\n",
       "                        [-1.0233e-01,  3.6819e-02,  3.7343e-02],\n",
       "                        [ 1.0334e-01, -3.0510e-05,  8.0785e-02]],\n",
       "              \n",
       "                       [[ 6.4612e-02,  7.6292e-02, -1.0460e-01],\n",
       "                        [ 8.6800e-02, -8.9856e-02,  9.4501e-02],\n",
       "                        [-4.3682e-03, -9.3415e-02,  2.9314e-02]],\n",
       "              \n",
       "                       [[-2.1456e-02, -9.4678e-02, -3.8215e-02],\n",
       "                        [ 1.0868e-02,  8.2098e-02, -3.2406e-02],\n",
       "                        [ 6.2610e-02,  1.3200e-02,  3.5531e-03]],\n",
       "              \n",
       "                       [[ 2.0170e-02, -6.9177e-02, -8.7616e-02],\n",
       "                        [-3.3121e-02, -9.8226e-02, -4.9158e-02],\n",
       "                        [ 4.8494e-03, -6.9424e-02, -4.3723e-02]],\n",
       "              \n",
       "                       [[-1.8941e-02, -1.2144e-02, -5.8187e-02],\n",
       "                        [ 5.0650e-03, -1.4795e-02,  3.0147e-02],\n",
       "                        [ 4.7611e-03, -5.2638e-02, -3.6291e-02]],\n",
       "              \n",
       "                       [[-1.2149e-03, -6.5774e-02,  8.2520e-03],\n",
       "                        [-7.4425e-03,  4.0897e-02,  2.4947e-02],\n",
       "                        [ 7.8887e-02, -3.4749e-03, -7.7887e-02]],\n",
       "              \n",
       "                       [[ 4.7119e-02, -7.1240e-02, -1.4489e-02],\n",
       "                        [-3.4132e-02, -3.9997e-02, -3.9000e-02],\n",
       "                        [ 9.6863e-02,  6.0342e-02,  2.9213e-02]],\n",
       "              \n",
       "                       [[ 9.8975e-02, -9.5524e-02,  1.7010e-02],\n",
       "                        [ 6.7481e-02,  7.0022e-02, -8.3890e-02],\n",
       "                        [ 3.7514e-02, -6.0050e-02, -4.1187e-03]],\n",
       "              \n",
       "                       [[-2.1996e-02, -8.8013e-02, -1.0055e-01],\n",
       "                        [-6.9349e-02,  4.7832e-02,  4.8218e-02],\n",
       "                        [-9.1681e-02, -3.9586e-02,  1.7218e-03]],\n",
       "              \n",
       "                       [[-9.1135e-02,  5.9393e-02,  9.5473e-02],\n",
       "                        [ 1.8643e-02, -7.8321e-02,  2.4580e-02],\n",
       "                        [ 3.8265e-02,  8.3468e-02, -5.6085e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.4437e-02,  4.6312e-02,  6.5624e-03],\n",
       "                        [-3.4345e-02, -4.4169e-02, -5.4351e-02],\n",
       "                        [ 8.5328e-02, -1.8187e-02,  7.6022e-02]],\n",
       "              \n",
       "                       [[ 9.4094e-02,  1.3353e-02,  2.2454e-02],\n",
       "                        [-7.1789e-03,  7.2397e-02, -9.4983e-02],\n",
       "                        [ 4.1919e-02, -1.7174e-02,  4.8132e-02]],\n",
       "              \n",
       "                       [[-4.6949e-04, -3.9029e-02, -1.1379e-02],\n",
       "                        [ 5.6920e-02, -7.3210e-02, -6.6629e-02],\n",
       "                        [-2.3611e-02, -3.8235e-02,  4.1409e-02]],\n",
       "              \n",
       "                       [[ 7.0937e-02, -1.1289e-02,  9.9672e-02],\n",
       "                        [-4.4042e-02, -5.9151e-02, -4.7191e-02],\n",
       "                        [-7.2624e-02, -7.3885e-02, -9.3921e-02]],\n",
       "              \n",
       "                       [[-9.3422e-02,  2.7512e-02,  6.4284e-02],\n",
       "                        [ 9.8963e-02,  8.9787e-02, -6.0709e-03],\n",
       "                        [ 2.0454e-02, -6.3068e-02,  4.0743e-02]],\n",
       "              \n",
       "                       [[-1.0107e-01,  4.9719e-02,  1.9334e-02],\n",
       "                        [ 3.2393e-02,  3.8595e-02, -4.8394e-02],\n",
       "                        [ 9.0452e-02,  5.0307e-02,  6.9243e-02]],\n",
       "              \n",
       "                       [[ 1.3922e-02,  6.6196e-02,  7.0941e-02],\n",
       "                        [ 4.7775e-02,  8.0297e-02, -1.9119e-02],\n",
       "                        [ 6.9310e-02,  2.4286e-02,  6.3424e-02]],\n",
       "              \n",
       "                       [[ 1.0267e-01,  2.3869e-02, -3.9124e-02],\n",
       "                        [-1.0488e-02,  2.9676e-02,  1.7773e-02],\n",
       "                        [-2.8795e-02,  8.2590e-02,  6.3331e-02]],\n",
       "              \n",
       "                       [[-6.5475e-02, -8.5889e-03, -1.0119e-02],\n",
       "                        [-6.6063e-02,  1.5374e-02, -3.2360e-02],\n",
       "                        [-5.4419e-02, -3.3894e-02, -3.7584e-02]],\n",
       "              \n",
       "                       [[ 1.0084e-01,  4.0432e-02,  1.0373e-01],\n",
       "                        [ 2.8903e-02,  2.3868e-02,  4.3333e-02],\n",
       "                        [ 1.8092e-02, -8.2722e-02, -6.2334e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5538e-02,  1.5846e-03,  3.9709e-02],\n",
       "                        [ 4.0588e-02,  8.3623e-02,  2.1458e-02],\n",
       "                        [-3.5975e-02, -7.9271e-02, -7.7203e-02]],\n",
       "              \n",
       "                       [[-6.2965e-02,  3.1792e-02,  5.6950e-02],\n",
       "                        [ 9.2224e-02, -3.3342e-02, -8.3150e-03],\n",
       "                        [-3.1303e-02, -3.8517e-04,  3.3837e-02]],\n",
       "              \n",
       "                       [[-2.3160e-03,  4.8799e-03,  1.3354e-02],\n",
       "                        [ 3.9256e-02, -3.1981e-02, -6.2855e-02],\n",
       "                        [ 2.4869e-02, -1.2481e-02, -4.7753e-02]],\n",
       "              \n",
       "                       [[ 4.4268e-02,  9.5597e-04, -1.5333e-02],\n",
       "                        [-5.1027e-02, -1.3868e-02, -8.9632e-02],\n",
       "                        [ 2.3980e-02,  1.5818e-03,  6.3966e-02]],\n",
       "              \n",
       "                       [[ 6.8063e-03,  8.4277e-03,  2.8715e-02],\n",
       "                        [ 8.0210e-02, -4.9812e-02,  6.2930e-02],\n",
       "                        [ 2.5779e-02, -7.0320e-02,  3.6702e-02]],\n",
       "              \n",
       "                       [[-6.3217e-02, -3.3181e-02, -5.0245e-02],\n",
       "                        [-7.1711e-02,  8.3017e-02, -9.4217e-02],\n",
       "                        [ 5.2706e-02, -9.4870e-02, -1.2829e-02]],\n",
       "              \n",
       "                       [[ 6.2868e-03,  7.4937e-02, -3.8147e-02],\n",
       "                        [ 3.0340e-02,  1.6329e-02,  6.2021e-02],\n",
       "                        [ 6.2668e-03,  3.9470e-02, -6.3677e-02]],\n",
       "              \n",
       "                       [[-7.3250e-02,  9.3928e-02, -7.6808e-02],\n",
       "                        [-1.7945e-02, -1.2742e-02,  1.0308e-01],\n",
       "                        [-2.2780e-02, -8.0249e-02, -2.6721e-02]],\n",
       "              \n",
       "                       [[ 5.4372e-02,  4.1773e-02,  8.7204e-02],\n",
       "                        [-2.1579e-02,  4.9653e-02, -9.9194e-02],\n",
       "                        [ 4.0787e-02,  4.8432e-02,  6.7998e-02]],\n",
       "              \n",
       "                       [[-6.0446e-02, -2.8142e-02,  2.5502e-02],\n",
       "                        [-7.4905e-02, -8.3851e-02, -1.0141e-01],\n",
       "                        [ 5.8842e-03,  6.5458e-02,  2.7075e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.4263e-03,  3.6727e-02, -6.6240e-02],\n",
       "                        [ 1.1113e-02, -2.6186e-02, -5.2193e-02],\n",
       "                        [ 9.0902e-02, -8.1550e-02,  1.5448e-02]],\n",
       "              \n",
       "                       [[-9.2624e-02, -3.5762e-03, -4.6840e-02],\n",
       "                        [ 3.4695e-02, -5.9191e-02,  6.7466e-02],\n",
       "                        [-8.5536e-02,  6.3313e-02, -7.9181e-02]],\n",
       "              \n",
       "                       [[ 5.6456e-02, -4.4384e-02, -2.4556e-04],\n",
       "                        [-1.9238e-02,  6.8414e-02,  3.4546e-02],\n",
       "                        [-9.2887e-02,  9.6914e-03, -7.2718e-02]],\n",
       "              \n",
       "                       [[ 7.8800e-02,  1.7319e-02, -2.7109e-02],\n",
       "                        [-5.3777e-02,  3.6485e-02, -6.3129e-02],\n",
       "                        [ 4.9992e-02,  5.7519e-02,  6.4701e-02]],\n",
       "              \n",
       "                       [[ 2.7537e-02, -9.2272e-02,  7.5823e-02],\n",
       "                        [-3.2700e-02, -3.1163e-02, -1.1325e-02],\n",
       "                        [ 7.7068e-02,  8.1052e-02,  1.6276e-02]],\n",
       "              \n",
       "                       [[ 5.0296e-02, -9.8241e-02,  2.4901e-04],\n",
       "                        [-9.3254e-02,  3.5876e-02, -7.5099e-02],\n",
       "                        [-3.7568e-02,  7.3684e-02,  1.0074e-01]],\n",
       "              \n",
       "                       [[-6.3286e-02, -5.8503e-02,  1.3055e-02],\n",
       "                        [ 4.1437e-02, -1.7168e-02, -3.2918e-02],\n",
       "                        [-6.9237e-02,  4.4997e-02,  1.0328e-01]],\n",
       "              \n",
       "                       [[-5.1026e-02,  4.9718e-02,  5.1481e-02],\n",
       "                        [ 8.4728e-02, -1.2001e-02,  3.3202e-03],\n",
       "                        [ 7.7444e-02,  6.6631e-02,  1.0411e-01]],\n",
       "              \n",
       "                       [[-3.0207e-02,  4.1709e-02,  7.3605e-02],\n",
       "                        [-7.1553e-02,  2.0940e-02, -2.3586e-02],\n",
       "                        [ 6.7760e-02, -4.7342e-02,  7.3933e-03]],\n",
       "              \n",
       "                       [[ 6.3067e-02, -9.6567e-02, -8.9004e-02],\n",
       "                        [-5.3989e-02,  6.7611e-02,  7.0680e-02],\n",
       "                        [-7.1991e-02,  2.0100e-02, -5.5854e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8926e-02,  9.0907e-02,  5.0914e-02],\n",
       "                        [-2.8828e-02,  1.5516e-02,  2.0424e-02],\n",
       "                        [ 2.4691e-02, -3.6079e-02, -6.2074e-02]],\n",
       "              \n",
       "                       [[ 6.9788e-02,  1.4164e-02,  4.4119e-02],\n",
       "                        [-3.9922e-02,  5.1057e-02,  7.6713e-02],\n",
       "                        [ 6.4107e-02,  2.8660e-02,  1.0371e-01]],\n",
       "              \n",
       "                       [[-2.3053e-04,  2.2441e-02,  1.0015e-01],\n",
       "                        [ 1.0245e-01, -4.4506e-02,  9.4953e-02],\n",
       "                        [ 3.8902e-02, -1.1799e-02,  9.2038e-02]],\n",
       "              \n",
       "                       [[-5.4605e-02,  6.8490e-02,  1.0445e-01],\n",
       "                        [-7.2701e-02, -6.2201e-02, -1.0445e-01],\n",
       "                        [-1.8970e-02, -9.5733e-02, -3.5304e-02]],\n",
       "              \n",
       "                       [[ 3.2002e-02,  7.4511e-02,  5.8717e-02],\n",
       "                        [ 5.8511e-02,  4.3730e-02, -6.5378e-02],\n",
       "                        [-8.3694e-02,  4.3696e-03,  1.0009e-01]],\n",
       "              \n",
       "                       [[ 5.9351e-03, -9.0662e-03, -7.1545e-02],\n",
       "                        [-5.2266e-02, -8.1256e-02,  8.4398e-02],\n",
       "                        [-1.7174e-02, -9.3119e-02,  1.1308e-02]],\n",
       "              \n",
       "                       [[ 7.6494e-03, -1.3023e-02,  3.7733e-02],\n",
       "                        [ 5.6687e-02, -9.9128e-02, -8.0753e-02],\n",
       "                        [-5.0639e-03, -9.7729e-02, -9.5750e-02]],\n",
       "              \n",
       "                       [[ 9.3067e-02, -8.0174e-03, -5.2113e-02],\n",
       "                        [-3.6157e-02, -8.2295e-02,  8.2258e-02],\n",
       "                        [-2.2857e-02, -5.9265e-02, -7.9944e-02]],\n",
       "              \n",
       "                       [[ 6.1611e-02, -1.4571e-02, -1.1074e-02],\n",
       "                        [-2.7473e-02, -5.0883e-02,  1.8751e-02],\n",
       "                        [ 8.1099e-02, -6.1093e-02,  5.0504e-03]],\n",
       "              \n",
       "                       [[-8.0165e-02, -4.9426e-02,  9.2525e-02],\n",
       "                        [ 1.1052e-03,  1.0154e-01, -1.8468e-02],\n",
       "                        [-5.7453e-02, -6.2981e-02,  9.3426e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.1058e-02,  5.5318e-02,  2.6203e-02],\n",
       "                        [ 3.1107e-02,  5.9476e-02, -2.7577e-02],\n",
       "                        [ 6.5223e-02, -8.3982e-02, -3.7087e-02]],\n",
       "              \n",
       "                       [[ 7.7164e-02,  3.1283e-02, -1.4038e-02],\n",
       "                        [-2.4616e-02, -6.4364e-02,  6.4098e-02],\n",
       "                        [-3.3520e-03, -3.5664e-03,  2.4929e-02]],\n",
       "              \n",
       "                       [[ 7.7787e-02, -5.3778e-02, -3.6303e-02],\n",
       "                        [ 7.1429e-02,  5.9532e-02, -5.1855e-02],\n",
       "                        [-1.0428e-01,  1.9555e-02,  5.5434e-02]],\n",
       "              \n",
       "                       [[ 2.5178e-02,  7.4768e-02, -8.3640e-02],\n",
       "                        [ 5.3156e-02, -6.5531e-02,  5.9325e-02],\n",
       "                        [ 7.8394e-02,  3.3385e-02,  8.5284e-02]],\n",
       "              \n",
       "                       [[-6.9481e-02, -9.4275e-02, -1.0135e-01],\n",
       "                        [ 6.6179e-02,  3.6926e-02, -7.7188e-02],\n",
       "                        [ 5.1048e-02,  9.6177e-02, -1.0394e-01]],\n",
       "              \n",
       "                       [[ 7.6466e-02,  1.6167e-02,  9.8053e-03],\n",
       "                        [ 9.4847e-02,  9.5458e-02,  4.4414e-02],\n",
       "                        [ 8.3288e-02,  4.3853e-02,  1.7176e-02]],\n",
       "              \n",
       "                       [[-9.2656e-02,  1.9689e-02, -7.4993e-02],\n",
       "                        [ 3.2452e-02,  1.8598e-02,  2.3681e-03],\n",
       "                        [-7.2071e-02, -6.3899e-02,  7.7912e-02]],\n",
       "              \n",
       "                       [[ 5.1336e-02,  5.5576e-02, -3.1410e-02],\n",
       "                        [-1.8151e-02, -2.7014e-02,  7.2489e-02],\n",
       "                        [-4.5504e-02,  6.6394e-02,  7.2679e-02]],\n",
       "              \n",
       "                       [[-9.6403e-02,  6.4369e-04, -2.0076e-02],\n",
       "                        [-5.8273e-02,  4.5507e-02, -1.2807e-02],\n",
       "                        [ 9.2287e-02, -6.5976e-02,  4.8976e-02]],\n",
       "              \n",
       "                       [[-8.9998e-02, -5.2833e-02,  7.1903e-03],\n",
       "                        [ 8.3283e-02,  5.5521e-02, -8.6550e-02],\n",
       "                        [ 1.1676e-02, -6.2138e-02,  4.5674e-03]]]])),\n",
       "             ('conv_block_2.0.bias',\n",
       "              tensor([-0.0878, -0.0309,  0.0723, -0.0967, -0.1005,  0.0192,  0.0144, -0.0193,\n",
       "                       0.0920, -0.0635])),\n",
       "             ('conv_block_2.2.weight',\n",
       "              tensor([[[[-6.3992e-02, -7.8791e-02, -1.9619e-02],\n",
       "                        [-2.6901e-02,  6.5222e-02, -5.9186e-03],\n",
       "                        [ 3.3663e-02, -4.3804e-02,  8.5507e-02]],\n",
       "              \n",
       "                       [[ 8.8862e-02, -9.4401e-02, -2.7090e-02],\n",
       "                        [-8.9439e-02,  4.4781e-02, -9.2094e-02],\n",
       "                        [-4.9839e-02,  1.0532e-01, -1.0066e-01]],\n",
       "              \n",
       "                       [[ 7.7771e-02,  8.9049e-03,  8.4289e-02],\n",
       "                        [-5.3494e-02,  6.9236e-02,  1.2718e-02],\n",
       "                        [ 8.1073e-03,  7.1945e-02, -1.0019e-01]],\n",
       "              \n",
       "                       [[-8.4902e-02,  1.0180e-01, -6.3298e-02],\n",
       "                        [-7.5980e-02, -5.1539e-03, -3.3742e-02],\n",
       "                        [-1.4421e-02, -7.0623e-02,  3.8034e-02]],\n",
       "              \n",
       "                       [[-9.0703e-02,  8.5374e-03,  6.1510e-02],\n",
       "                        [ 2.0253e-02,  1.4006e-02,  1.5418e-02],\n",
       "                        [-3.0880e-02, -2.0080e-02, -4.4450e-02]],\n",
       "              \n",
       "                       [[-7.1207e-02, -5.5810e-02,  1.0420e-01],\n",
       "                        [-1.7641e-02,  3.6924e-02,  7.2896e-02],\n",
       "                        [-8.2343e-03, -5.6707e-02, -7.1419e-02]],\n",
       "              \n",
       "                       [[-3.8833e-02,  3.7624e-02, -8.8771e-02],\n",
       "                        [-1.2870e-02,  4.0096e-02,  8.5999e-02],\n",
       "                        [ 3.1721e-02,  2.0846e-02,  7.2162e-02]],\n",
       "              \n",
       "                       [[ 4.8708e-02,  3.5661e-02, -3.2682e-02],\n",
       "                        [-8.4528e-02, -2.2769e-02, -1.9117e-02],\n",
       "                        [ 7.7410e-03, -1.1593e-02,  4.2616e-02]],\n",
       "              \n",
       "                       [[ 7.0050e-02, -4.2735e-02, -1.0002e-01],\n",
       "                        [-5.4081e-02, -5.0436e-02,  5.9750e-02],\n",
       "                        [-6.7994e-02, -9.9145e-03, -2.2340e-02]],\n",
       "              \n",
       "                       [[-6.3976e-02,  4.7780e-02, -4.3909e-02],\n",
       "                        [-5.4531e-03, -7.4112e-02, -1.0632e-02],\n",
       "                        [ 1.4977e-02, -4.2894e-03, -3.9386e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.1315e-02, -2.7311e-02, -5.8439e-02],\n",
       "                        [-7.7732e-02, -2.2329e-02, -9.9578e-02],\n",
       "                        [ 8.7492e-02, -5.0357e-02, -4.3684e-02]],\n",
       "              \n",
       "                       [[ 9.7439e-03,  2.7326e-02, -9.9393e-03],\n",
       "                        [ 7.2313e-02, -6.1448e-02,  3.7777e-02],\n",
       "                        [-2.3773e-04, -8.5747e-02, -4.0824e-02]],\n",
       "              \n",
       "                       [[ 2.6825e-02,  2.0138e-02,  7.6647e-02],\n",
       "                        [ 7.0518e-02, -5.7493e-02, -4.5013e-02],\n",
       "                        [-2.2351e-02, -7.5517e-02, -2.8459e-02]],\n",
       "              \n",
       "                       [[-8.6258e-02,  4.0092e-02,  7.4583e-02],\n",
       "                        [ 8.3459e-03, -7.5460e-02, -7.9827e-02],\n",
       "                        [-4.1036e-02,  3.0659e-02,  2.5711e-03]],\n",
       "              \n",
       "                       [[ 1.9166e-02,  9.9346e-02,  4.8956e-02],\n",
       "                        [ 2.2665e-02, -2.1327e-02,  4.9864e-02],\n",
       "                        [ 3.8563e-02, -9.4879e-02, -6.2266e-02]],\n",
       "              \n",
       "                       [[ 3.5381e-03,  3.9997e-02,  5.1282e-02],\n",
       "                        [-6.2748e-02, -1.0458e-01, -5.4909e-03],\n",
       "                        [-1.2050e-02,  3.0588e-02, -2.8988e-02]],\n",
       "              \n",
       "                       [[ 8.0588e-02,  7.0333e-03,  7.6975e-02],\n",
       "                        [-7.3398e-02,  4.2167e-02,  1.2560e-02],\n",
       "                        [-5.2720e-02,  5.2256e-02, -1.0372e-01]],\n",
       "              \n",
       "                       [[ 8.5220e-02,  8.4947e-03,  1.0178e-02],\n",
       "                        [ 4.8746e-02,  8.7503e-03,  4.5184e-02],\n",
       "                        [ 6.7063e-02, -8.2268e-02,  6.9735e-02]],\n",
       "              \n",
       "                       [[-1.5784e-02, -2.4513e-02,  2.1217e-02],\n",
       "                        [ 8.2446e-02, -5.7302e-02, -7.1039e-02],\n",
       "                        [ 6.5418e-02, -4.9507e-02,  3.3937e-02]],\n",
       "              \n",
       "                       [[-1.5530e-02,  2.9014e-02,  8.0439e-02],\n",
       "                        [-5.3421e-02, -5.1151e-02,  5.1716e-02],\n",
       "                        [ 5.7714e-03, -1.1601e-02, -9.2590e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.9309e-02, -3.9919e-03, -1.9415e-02],\n",
       "                        [-4.3269e-02, -2.0801e-02,  5.1233e-02],\n",
       "                        [-2.4227e-03,  9.0147e-02, -6.0858e-03]],\n",
       "              \n",
       "                       [[-1.5122e-02,  5.9498e-02, -2.7275e-03],\n",
       "                        [-2.1039e-02,  3.5231e-02,  8.3129e-02],\n",
       "                        [ 2.6305e-02,  7.3398e-02,  6.8309e-02]],\n",
       "              \n",
       "                       [[ 2.9810e-02,  3.6650e-02,  3.4014e-02],\n",
       "                        [ 1.0934e-02,  8.9675e-02,  9.7308e-02],\n",
       "                        [ 3.7524e-02, -5.2640e-03,  9.4509e-02]],\n",
       "              \n",
       "                       [[-8.2042e-02,  7.7453e-02,  5.5849e-02],\n",
       "                        [ 6.7687e-02, -8.0992e-03, -7.8646e-02],\n",
       "                        [ 7.5193e-02, -4.6091e-02,  2.7734e-02]],\n",
       "              \n",
       "                       [[ 5.9719e-02, -9.8508e-02,  6.9954e-03],\n",
       "                        [-3.7444e-02,  7.4815e-02, -6.7114e-02],\n",
       "                        [ 6.4001e-02,  6.5730e-02,  5.8156e-02]],\n",
       "              \n",
       "                       [[ 1.0119e-01,  1.5964e-02, -9.5541e-02],\n",
       "                        [ 7.5248e-02,  9.6499e-03,  2.0918e-03],\n",
       "                        [-1.0041e-01, -2.3691e-02, -5.1162e-02]],\n",
       "              \n",
       "                       [[ 1.0324e-01,  7.5054e-02,  7.8634e-02],\n",
       "                        [ 7.2188e-02, -6.5340e-02, -4.5270e-02],\n",
       "                        [-4.1252e-02, -4.2257e-02,  8.2054e-02]],\n",
       "              \n",
       "                       [[ 3.5815e-02,  8.4470e-02, -4.9309e-03],\n",
       "                        [-9.3965e-02, -3.0582e-02,  7.4081e-02],\n",
       "                        [ 6.4174e-02,  3.2632e-02, -3.0919e-02]],\n",
       "              \n",
       "                       [[-9.8386e-02, -5.6639e-02,  5.4958e-02],\n",
       "                        [-4.2518e-02,  5.0421e-02,  2.8781e-02],\n",
       "                        [-4.0486e-02,  6.4202e-02, -3.3871e-02]],\n",
       "              \n",
       "                       [[-3.5020e-03, -4.0152e-02, -9.9988e-02],\n",
       "                        [ 1.6996e-02,  3.0460e-02, -5.3072e-02],\n",
       "                        [ 6.4663e-02, -9.4558e-02, -1.0161e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.5106e-02, -3.6430e-02, -1.1707e-02],\n",
       "                        [-2.0370e-02,  4.8108e-02, -9.2510e-02],\n",
       "                        [ 1.5521e-02,  1.8254e-03,  2.7842e-02]],\n",
       "              \n",
       "                       [[ 1.0479e-01,  6.4874e-02, -5.8366e-02],\n",
       "                        [-8.6378e-02, -2.5520e-02, -5.2876e-02],\n",
       "                        [ 3.6820e-02,  9.6628e-04,  8.4783e-02]],\n",
       "              \n",
       "                       [[ 4.1405e-02, -1.9382e-02,  3.6229e-03],\n",
       "                        [ 2.5244e-02, -1.3080e-02,  8.5058e-02],\n",
       "                        [-8.2420e-02,  5.1377e-02, -6.7192e-02]],\n",
       "              \n",
       "                       [[-9.2347e-02, -2.1640e-02,  5.1366e-02],\n",
       "                        [ 7.4478e-02,  2.6452e-02, -9.1104e-03],\n",
       "                        [-5.9092e-03, -4.2731e-02, -9.4592e-03]],\n",
       "              \n",
       "                       [[-7.2831e-03,  8.9699e-02,  6.1690e-02],\n",
       "                        [-8.4351e-02,  4.3605e-04, -6.4834e-02],\n",
       "                        [-1.6733e-02, -8.3776e-02,  2.7402e-02]],\n",
       "              \n",
       "                       [[-7.6008e-02,  1.0406e-01,  7.9605e-02],\n",
       "                        [-7.2559e-02, -9.9239e-02,  4.1128e-03],\n",
       "                        [-2.9425e-02,  3.0945e-02, -7.1353e-02]],\n",
       "              \n",
       "                       [[ 4.3148e-02, -9.1047e-02, -5.5632e-02],\n",
       "                        [-5.5414e-02,  5.1007e-02, -2.7597e-03],\n",
       "                        [-1.0130e-01, -6.0201e-02, -4.8781e-02]],\n",
       "              \n",
       "                       [[-9.7802e-02,  1.3497e-02,  3.7561e-02],\n",
       "                        [-1.9340e-02, -4.1947e-02, -6.3926e-04],\n",
       "                        [-8.3725e-02, -6.4184e-02, -2.4040e-03]],\n",
       "              \n",
       "                       [[ 9.3643e-02, -3.2414e-02,  5.2247e-02],\n",
       "                        [-4.1484e-02, -2.8060e-02, -1.0034e-01],\n",
       "                        [ 8.7330e-02,  1.0264e-01, -2.2139e-03]],\n",
       "              \n",
       "                       [[ 6.6974e-02,  8.6219e-02,  5.2359e-02],\n",
       "                        [ 5.4288e-02, -1.0035e-01, -9.9050e-02],\n",
       "                        [-8.0906e-02,  3.2970e-02, -9.1177e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.0464e-02, -5.1092e-02, -9.7154e-02],\n",
       "                        [ 1.4203e-04,  1.5207e-02, -6.1686e-02],\n",
       "                        [ 6.9018e-02, -4.0018e-02, -2.9676e-02]],\n",
       "              \n",
       "                       [[ 8.0309e-02,  9.0499e-02, -1.2093e-02],\n",
       "                        [-7.5671e-02, -5.2881e-02,  1.3423e-02],\n",
       "                        [ 6.1790e-02,  5.2477e-02, -4.6547e-02]],\n",
       "              \n",
       "                       [[-9.9650e-02, -9.2249e-02, -3.3537e-02],\n",
       "                        [ 1.3223e-03, -4.7347e-02, -8.3348e-02],\n",
       "                        [ 1.1109e-02, -8.3668e-02, -8.0946e-02]],\n",
       "              \n",
       "                       [[-8.5692e-02, -2.8563e-02,  9.3104e-02],\n",
       "                        [ 4.1207e-02, -1.2498e-02,  2.1694e-02],\n",
       "                        [ 4.1975e-02,  6.1414e-04, -8.5020e-02]],\n",
       "              \n",
       "                       [[-6.4944e-02, -7.1610e-02, -2.6766e-03],\n",
       "                        [-9.6492e-02, -1.9166e-02, -3.8545e-02],\n",
       "                        [ 1.0345e-01,  8.5679e-02,  6.1227e-02]],\n",
       "              \n",
       "                       [[ 5.9116e-03, -3.4129e-02,  2.6887e-02],\n",
       "                        [-7.2830e-02, -4.4957e-02, -2.1175e-02],\n",
       "                        [-2.4766e-02, -9.9854e-02,  4.1903e-02]],\n",
       "              \n",
       "                       [[ 8.6803e-02, -5.8141e-02,  2.8415e-02],\n",
       "                        [-1.2225e-02, -3.8445e-03,  6.1443e-03],\n",
       "                        [ 9.1346e-02,  1.4124e-02, -6.6690e-02]],\n",
       "              \n",
       "                       [[-3.7917e-02,  5.1495e-02,  3.2893e-02],\n",
       "                        [ 2.0487e-03, -1.3912e-02, -4.1012e-02],\n",
       "                        [-3.7413e-02, -5.5602e-02,  1.7273e-02]],\n",
       "              \n",
       "                       [[ 2.9603e-02,  8.0717e-02, -2.3813e-02],\n",
       "                        [ 7.5461e-03,  6.8125e-02,  4.5852e-02],\n",
       "                        [ 1.3544e-02,  3.2390e-02,  5.4714e-03]],\n",
       "              \n",
       "                       [[-9.0419e-02,  4.0636e-03, -2.3040e-02],\n",
       "                        [ 9.5123e-02,  9.5145e-02,  2.0912e-02],\n",
       "                        [ 9.4215e-02, -5.4288e-02,  9.1619e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.0756e-02, -4.0288e-03, -8.4592e-02],\n",
       "                        [-3.4015e-02, -2.8189e-02,  1.7411e-03],\n",
       "                        [-9.5569e-02,  1.9535e-02, -4.3839e-02]],\n",
       "              \n",
       "                       [[-2.6989e-02, -5.4443e-02, -2.2255e-02],\n",
       "                        [-9.7896e-02, -5.5885e-02,  9.7108e-03],\n",
       "                        [ 6.9072e-02,  9.5790e-02, -7.9737e-02]],\n",
       "              \n",
       "                       [[ 4.4264e-02, -5.9419e-02, -8.1498e-02],\n",
       "                        [-4.6417e-03, -6.0468e-02, -9.0783e-02],\n",
       "                        [-9.8509e-02, -7.0556e-02,  8.6619e-02]],\n",
       "              \n",
       "                       [[ 5.8788e-02, -4.1726e-02, -7.0553e-02],\n",
       "                        [-8.1085e-02, -6.2246e-02, -4.3376e-02],\n",
       "                        [ 6.3308e-02,  3.4496e-02, -4.0622e-02]],\n",
       "              \n",
       "                       [[ 7.2567e-02, -6.5484e-02, -8.5876e-02],\n",
       "                        [ 2.3006e-02, -5.8123e-02,  2.9987e-02],\n",
       "                        [ 8.9306e-02, -4.9849e-02, -7.3556e-02]],\n",
       "              \n",
       "                       [[ 3.9676e-02, -9.5200e-02,  9.4044e-02],\n",
       "                        [-4.9780e-02,  5.0961e-02, -8.3818e-02],\n",
       "                        [-7.1348e-02,  1.1611e-02,  3.7463e-02]],\n",
       "              \n",
       "                       [[ 8.1734e-02,  8.8158e-02, -6.0623e-03],\n",
       "                        [-1.3552e-02,  1.7424e-02, -2.4486e-02],\n",
       "                        [ 3.5882e-03, -9.9828e-02, -8.6531e-02]],\n",
       "              \n",
       "                       [[ 7.2233e-02, -6.1597e-02,  8.3008e-02],\n",
       "                        [ 1.1568e-02,  2.5676e-02,  9.5804e-02],\n",
       "                        [-5.8628e-02, -1.6640e-02,  1.8675e-02]],\n",
       "              \n",
       "                       [[ 3.6012e-02, -1.0259e-01,  3.7464e-02],\n",
       "                        [-6.2163e-02,  1.3846e-02,  7.1315e-02],\n",
       "                        [-1.0500e-02, -3.3346e-03, -7.8757e-03]],\n",
       "              \n",
       "                       [[ 8.7962e-02,  5.9907e-02,  1.7727e-02],\n",
       "                        [-6.3437e-02, -5.7241e-02,  8.3964e-02],\n",
       "                        [ 7.5834e-02,  6.1033e-02, -8.2189e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.2092e-02, -1.0076e-02,  7.7661e-02],\n",
       "                        [ 9.1553e-02,  1.1554e-02, -4.3863e-02],\n",
       "                        [ 9.9153e-02, -5.4931e-02,  6.8876e-02]],\n",
       "              \n",
       "                       [[-1.0108e-01, -3.3153e-02, -9.1902e-02],\n",
       "                        [-4.7284e-02,  4.4759e-02, -7.5529e-02],\n",
       "                        [-9.1158e-02,  7.5371e-02,  5.6270e-02]],\n",
       "              \n",
       "                       [[-1.1527e-03, -7.4309e-02, -2.7927e-02],\n",
       "                        [-3.4129e-02,  6.5100e-02, -3.4478e-02],\n",
       "                        [-3.0360e-02, -7.4720e-02, -4.9646e-02]],\n",
       "              \n",
       "                       [[ 5.7074e-02,  6.7914e-02,  1.5315e-02],\n",
       "                        [-3.9549e-02,  1.0124e-01,  2.0806e-02],\n",
       "                        [-4.0688e-02, -3.6535e-02, -1.4752e-02]],\n",
       "              \n",
       "                       [[ 4.9974e-02,  3.8555e-02,  7.6418e-02],\n",
       "                        [-4.7494e-03,  8.7183e-02, -4.2816e-02],\n",
       "                        [-4.8547e-02, -3.8927e-02, -9.8896e-02]],\n",
       "              \n",
       "                       [[-6.9195e-02, -9.5382e-02, -6.2294e-03],\n",
       "                        [ 9.9374e-04, -2.7358e-02, -7.2035e-02],\n",
       "                        [ 9.5637e-02, -3.4926e-02,  5.0233e-02]],\n",
       "              \n",
       "                       [[ 7.3408e-02, -6.9292e-02, -1.3179e-02],\n",
       "                        [ 6.0923e-02,  1.0218e-01, -1.3299e-02],\n",
       "                        [ 7.6382e-02, -8.2732e-02, -6.8489e-02]],\n",
       "              \n",
       "                       [[ 8.6682e-02, -9.9801e-03,  1.0414e-01],\n",
       "                        [ 7.6651e-03, -4.3714e-02,  1.0011e-01],\n",
       "                        [ 9.2179e-02,  9.7826e-03, -6.3900e-02]],\n",
       "              \n",
       "                       [[-4.5639e-03, -5.0693e-02,  7.6810e-02],\n",
       "                        [ 4.8829e-03,  2.2191e-02,  6.3927e-02],\n",
       "                        [ 3.4916e-02, -6.5803e-02,  8.7566e-02]],\n",
       "              \n",
       "                       [[ 6.4758e-02, -6.5073e-02,  7.9700e-02],\n",
       "                        [ 2.9905e-02, -2.0750e-02, -7.5385e-02],\n",
       "                        [-1.7490e-02, -1.0335e-01,  6.0163e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.6343e-02, -3.0347e-02,  9.7720e-02],\n",
       "                        [-3.9032e-02,  1.8051e-02, -7.3459e-02],\n",
       "                        [-4.4565e-03,  4.2610e-02,  4.5403e-02]],\n",
       "              \n",
       "                       [[-3.5346e-03, -5.3154e-02,  7.3680e-02],\n",
       "                        [ 6.9788e-02,  1.6916e-02, -4.8475e-02],\n",
       "                        [ 2.2349e-02,  2.8186e-04,  9.6302e-02]],\n",
       "              \n",
       "                       [[ 1.5621e-02,  8.1301e-03,  7.2057e-03],\n",
       "                        [ 5.6079e-02, -1.3024e-03,  9.0351e-02],\n",
       "                        [ 5.4917e-02, -7.9650e-02, -1.2070e-06]],\n",
       "              \n",
       "                       [[-8.9472e-02, -8.0934e-02,  2.0480e-02],\n",
       "                        [ 2.3687e-02, -9.2246e-03,  1.0019e-01],\n",
       "                        [-5.6627e-02, -4.4176e-02, -1.6881e-02]],\n",
       "              \n",
       "                       [[ 6.3911e-04, -8.9284e-03,  9.4909e-02],\n",
       "                        [-4.4519e-02, -5.5137e-02,  9.0599e-03],\n",
       "                        [ 7.9171e-02,  2.5019e-02,  5.6787e-02]],\n",
       "              \n",
       "                       [[ 2.0406e-02,  8.9839e-02,  6.3311e-02],\n",
       "                        [ 7.5428e-02, -1.4198e-02, -8.7268e-02],\n",
       "                        [-5.0002e-02,  3.5910e-02,  7.3950e-02]],\n",
       "              \n",
       "                       [[-4.1184e-02,  8.7218e-02,  1.5150e-02],\n",
       "                        [ 4.1869e-04,  4.1093e-03, -1.8623e-02],\n",
       "                        [ 9.8683e-02,  4.5784e-03,  6.4564e-02]],\n",
       "              \n",
       "                       [[-8.8967e-02, -5.4309e-02,  1.1852e-02],\n",
       "                        [ 8.4169e-02,  5.0184e-02,  2.0076e-02],\n",
       "                        [-1.0414e-01,  1.9816e-03, -6.9581e-02]],\n",
       "              \n",
       "                       [[-9.0006e-02,  1.4414e-02, -6.6693e-02],\n",
       "                        [ 9.5674e-02, -5.7294e-02,  3.3970e-02],\n",
       "                        [ 6.1871e-02, -8.1928e-02,  5.3946e-02]],\n",
       "              \n",
       "                       [[-1.4114e-02,  5.4619e-02,  1.0201e-01],\n",
       "                        [-4.4922e-02, -4.5653e-02,  8.3753e-02],\n",
       "                        [ 1.1722e-02, -1.0513e-02,  7.9971e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0928e-02, -5.2047e-03,  7.2403e-02],\n",
       "                        [ 4.1195e-02, -6.8180e-02,  2.7398e-02],\n",
       "                        [-8.0368e-02, -5.7245e-02,  6.7779e-02]],\n",
       "              \n",
       "                       [[-2.8093e-02, -5.3691e-02,  7.4717e-03],\n",
       "                        [ 2.5759e-02, -6.5524e-02, -7.1084e-02],\n",
       "                        [-1.0209e-01,  2.7236e-02, -6.8013e-02]],\n",
       "              \n",
       "                       [[ 8.0331e-03, -2.3576e-02, -6.8923e-02],\n",
       "                        [-3.3636e-02, -8.1027e-02, -5.5797e-02],\n",
       "                        [-3.2857e-03, -9.0116e-02, -9.2447e-02]],\n",
       "              \n",
       "                       [[ 7.8958e-02,  9.9188e-03, -4.6618e-02],\n",
       "                        [-3.5047e-03,  7.8168e-02, -8.7939e-02],\n",
       "                        [-5.5886e-02, -7.6226e-02, -7.6634e-03]],\n",
       "              \n",
       "                       [[-3.6274e-03, -8.2146e-02,  7.3163e-02],\n",
       "                        [-8.0946e-02,  9.8414e-02, -7.2560e-02],\n",
       "                        [-1.4446e-02,  1.9710e-02, -4.6852e-02]],\n",
       "              \n",
       "                       [[ 9.6939e-02, -7.2673e-02, -5.8427e-03],\n",
       "                        [-7.7398e-02,  2.9261e-02,  8.9871e-02],\n",
       "                        [ 9.7776e-02,  1.2514e-02, -5.2773e-02]],\n",
       "              \n",
       "                       [[ 1.0244e-01,  7.8667e-03,  7.1317e-02],\n",
       "                        [-5.4751e-02, -4.8920e-02, -8.7504e-02],\n",
       "                        [ 9.6990e-02,  1.7486e-02, -7.5704e-02]],\n",
       "              \n",
       "                       [[ 9.0535e-03, -4.5211e-02,  5.2659e-03],\n",
       "                        [ 3.4988e-02, -5.2308e-02,  1.8394e-02],\n",
       "                        [-6.6553e-02,  2.0312e-02, -1.0178e-01]],\n",
       "              \n",
       "                       [[ 1.6797e-02,  1.0473e-01,  9.7094e-02],\n",
       "                        [ 3.8451e-02,  7.7563e-02,  1.0248e-01],\n",
       "                        [ 2.9870e-02,  3.5156e-02,  1.3707e-02]],\n",
       "              \n",
       "                       [[ 9.3322e-02,  9.0551e-02, -4.9570e-02],\n",
       "                        [-4.3333e-03, -5.3110e-02,  3.7824e-02],\n",
       "                        [-1.0214e-01,  3.7301e-02, -2.8929e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.8227e-02,  3.2899e-02, -5.2454e-02],\n",
       "                        [ 5.4687e-02,  4.4762e-02, -8.9602e-02],\n",
       "                        [ 1.0517e-01,  9.0731e-02,  6.5584e-02]],\n",
       "              \n",
       "                       [[-1.0699e-02,  3.7345e-02, -5.7028e-02],\n",
       "                        [-3.5818e-02,  4.9749e-02,  4.6925e-02],\n",
       "                        [ 4.1741e-02, -1.0053e-01,  8.7350e-02]],\n",
       "              \n",
       "                       [[-4.4028e-02,  9.1223e-02,  8.6852e-02],\n",
       "                        [ 3.9070e-02,  1.0502e-01,  6.0528e-02],\n",
       "                        [ 6.1821e-02, -3.5794e-02,  9.7766e-02]],\n",
       "              \n",
       "                       [[ 2.7627e-02,  6.2280e-02, -2.3834e-02],\n",
       "                        [ 7.6340e-02,  9.3509e-02, -8.0770e-02],\n",
       "                        [ 8.6415e-02, -6.9664e-02, -7.2571e-02]],\n",
       "              \n",
       "                       [[-8.8089e-02,  3.0459e-02, -7.9144e-02],\n",
       "                        [-3.9680e-02, -5.2988e-02,  2.8172e-02],\n",
       "                        [-1.0349e-01, -4.8324e-02,  7.7112e-04]],\n",
       "              \n",
       "                       [[ 9.4660e-03, -4.7605e-02,  3.7764e-02],\n",
       "                        [-6.9544e-02, -8.9270e-02, -1.4986e-02],\n",
       "                        [-5.6989e-02,  6.6443e-02, -7.2049e-02]],\n",
       "              \n",
       "                       [[-8.8494e-03,  4.3782e-02, -9.2311e-02],\n",
       "                        [ 8.1599e-02, -4.7895e-02, -2.8684e-02],\n",
       "                        [-6.4480e-02, -3.9279e-02, -4.0645e-02]],\n",
       "              \n",
       "                       [[-9.3801e-02,  3.6019e-02, -3.3768e-04],\n",
       "                        [ 1.0311e-01,  7.1117e-02,  9.1699e-02],\n",
       "                        [ 3.1014e-02,  5.5388e-02,  9.8704e-02]],\n",
       "              \n",
       "                       [[ 8.6545e-02, -8.0996e-02, -2.3636e-02],\n",
       "                        [-1.0166e-01,  3.9877e-03, -3.7229e-02],\n",
       "                        [ 9.1486e-02,  1.6666e-02,  1.1601e-03]],\n",
       "              \n",
       "                       [[-7.6248e-02, -8.2718e-02,  1.6594e-02],\n",
       "                        [-5.2376e-02, -4.8409e-02,  7.3938e-02],\n",
       "                        [-5.4952e-02, -4.6918e-02,  8.0934e-02]]]])),\n",
       "             ('conv_block_2.2.bias',\n",
       "              tensor([ 0.0412, -0.0599,  0.0319,  0.0531, -0.0936,  0.0197,  0.0241, -0.0041,\n",
       "                       0.1011, -0.0697])),\n",
       "             ('classifier.1.weight', tensor([], size=(10, 0))),\n",
       "             ('classifier.1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "class_names = 10\n",
    "model_2 = FashionMNISTModelV2(input_shape=1,\n",
    "                              hidden_units=10,\n",
    "                              output_shape=10).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1 Stepping through nn.Conv2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([1, 1, 28, 20])\n",
      "Single image shape:\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "images = torch.randn(size=(1, 1, 28, 20))\n",
    "test_img = image[0].repeat(1, 3, 1, 1)\n",
    "print(f\"Image batch shape: {images.shape}\")\n",
    "print(f\"Single image shape:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 28, 28])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 26, 26])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Create a single conv2d layer\n",
    "conv_layer = nn.Conv2d(in_channels=3,\n",
    "                       out_channels=10,\n",
    "                       kernel_size=(5, 5),\n",
    "                       stride=1,\n",
    "                       padding=1)\n",
    "\n",
    "#Pass the data through the convolutional layer\n",
    "conv_output = conv_layer(test_img)\n",
    "conv_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 28, 28])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.1+cu118'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.2 Stepping through nn.MaxPool2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 28, 28])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image original shape: torch.Size([1, 3, 28, 28])\n",
      "Test image with unsqueezed dimensione: torch.Size([1, 1, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#Print ut original image shape without unsqueezed dimension\n",
    "print(f\"Test image original shape: { test_img.shape}\")\n",
    "print(f\"Test image with unsqueezed dimensione: { test_img.unsqueeze(0).shape}\")\n",
    "\n",
    "#Create a sample nn.MaxPool2d layer\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "# Pass data through just the conv layer\n",
    "test_image_through_conv = conv_layer(test_img.unsqueeze(dim=0))\n",
    "print(f\"Shape after going through conv layer(): {test_image_through_conv.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
